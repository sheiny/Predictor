{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb56f37",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7846cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "from enum import Enum\n",
    "import imblearn\n",
    "import time\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea80aed",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8209cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_positive_ratio(train_labels):\n",
    "  neg, pos = np.bincount(train_labels)\n",
    "  total = neg + pos\n",
    "  print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "# Claculate weight for classes\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "def calculate_class_weights(train_labels):\n",
    "  if True in train_labels and False in train_labels:\n",
    "    neg, pos = np.bincount(train_labels)\n",
    "    total = neg + pos\n",
    "    weight_for_0 = (1 / neg)*(total)/2.0 \n",
    "    weight_for_1 = (1 / pos)*(total)/2.0\n",
    "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "    print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "    print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
    "    return class_weight\n",
    "  else:\n",
    "    print('Using default weights(1, 1) due to the absence of either a positive or negative sample.')\n",
    "    return {0: 1, 1: 1}\n",
    "\n",
    "def oversample(train_array, train_labels):\n",
    "  oversample = RandomOverSampler()\n",
    "  train_array, train_labels = oversample.fit_resample(train_array, train_labels)\n",
    "  return train_array, train_labels\n",
    "\n",
    "def undersample(train_array, train_labels):\n",
    "  undersample = RandomUnderSampler()\n",
    "  train_array, train_labels = undersample.fit_resample(train_array, train_labels)\n",
    "  return train_array, train_labels\n",
    "\n",
    "########## Learning Model ##########\n",
    "def make_model(evalMetrics, dropOut, learningRate, inputSize, numNodes, numLayers):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Input(shape=inputSize))\n",
    "  for x in range(numLayers):\n",
    "    model.add(tf.keras.layers.Dense(numNodes, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(dropOut))\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learningRate),\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics=evalMetrics)\n",
    "  return model\n",
    "\n",
    "def calculateMetrics(tp, fp, tn, fn):\n",
    "  if tp == 0: #meaningless performance (always predict no viol or there is no viol in labels)\n",
    "    return 0, 0, 0, 0, -1 #return precision, recall, accuracy, fscore, mcc\n",
    "  precision = tp/(tp + fp)\n",
    "  recall = tp/(tp + fn)\n",
    "  accuracy = (tp + tn)/(tp + fn + tn + fp)\n",
    "  fscore = (2 * precision * recall)/(precision + recall)\n",
    "  sqrt = math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "  mcc = -1\n",
    "  if sqrt != 0:\n",
    "    mcc = ((tp * tn) - (fp * fn))/sqrt\n",
    "  return precision, recall, accuracy, fscore, mcc\n",
    "\n",
    "def numLines(file):\n",
    "  lines = 0\n",
    "  with open(file) as fp:\n",
    "    for _ in fp:\n",
    "      lines += 1\n",
    "  return lines\n",
    "\n",
    "class BalanceStrategy(Enum):\n",
    "  NONE = 0\n",
    "  WEIGHTS = 1\n",
    "  OVERSAMPLE = 2\n",
    "  UNDERSAMPLE = 3\n",
    "\n",
    "class ValidationReader():\n",
    "  def __init__(self, filePath, validationChunkSize):\n",
    "    self.filePath = filePath\n",
    "    self.validationChunkSize = validationChunkSize\n",
    "    self.currentItr = 0\n",
    "\n",
    "    valSizeRows = numLines(self.filePath) - 1 #skip header counting\n",
    "    self.valChunkIterations = int(valSizeRows/validationChunkSize) #disregard last lines\n",
    "    self.reader = pd.read_csv(self.filePath, dtype=np.float32, iterator=True)\n",
    "\n",
    "  def getChunk(self):\n",
    "    if self.currentItr == self.valChunkIterations:\n",
    "      self.reader = pd.read_csv(self.filePath, dtype=np.float32, iterator=True)\n",
    "      self.currentItr = 0\n",
    "    self.currentItr += 1\n",
    "    return self.reader.get_chunk(self.validationChunkSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e54192",
   "metadata": {},
   "source": [
    "# Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ac196",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = BalanceStrategy.WEIGHTS\n",
    "batch_size = 32 # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "numEpochs = 10\n",
    "learningRate = 0.001 #Eh?Predictor=0.05, default=0.001\n",
    "dropOut = 0.05 #Eh?Predictor=0.05\n",
    "evalMetrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "               tf.keras.metrics.FalsePositives(name='fp'),\n",
    "               tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "               tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall'),\n",
    "               tf.keras.metrics.AUC(name='auc')]\n",
    "scaler = pickle.load(open('data/scaler.pkl','rb'))\n",
    "testCSVFile = 'data/test.csv'\n",
    "validationCSVFile = 'data/validation.csv'\n",
    "testChunkSize = 1e6 # 1e6 ~= 10 iterations to cover whole train dataset\n",
    "validationChunkSize = int(testChunkSize * 0.2)\n",
    "valReader = ValidationReader(validationCSVFile, validationChunkSize)\n",
    "\n",
    "resultMetrics = ['TrainingRuntime', 'val_auc', 'auc', 'val_loss', 'loss',\n",
    "                 'tp', 'fp', 'tn', 'fn', 'accuracy', 'precision', 'recall', 'fscore', 'mcc',\n",
    "                 'val_tp', 'val_fp', 'val_tn', 'val_fn', 'val_accuracy', 'val_precision', 'val_recall',\n",
    "                 'val_fscore', 'val_mcc']\n",
    "\n",
    "for numNodes in [50, 100]:\n",
    "  for numLayers in range(1,3):\n",
    "    modelPath = 'savedModels/DNN_'+str(numLayers)+'L_'+str(numNodes)+'N'\n",
    "    if os.path.exists(modelPath):\n",
    "      shutil.rmtree(modelPath)\n",
    "    os.mkdir(modelPath)\n",
    "    os.mkdir(modelPath+'/model')\n",
    "    os.mkdir(modelPath+'/modelWeights')\n",
    "\n",
    "    inputSize = len(pd.read_csv(testCSVFile, nrows=1).columns)-2 # -2 to remove NodeID and label\n",
    "    model = make_model(evalMetrics, dropOut, learningRate, inputSize, numNodes, numLayers)\n",
    "\n",
    "    finalResults = {x:[] for x in resultMetrics}\n",
    "    for epoch in range(numEpochs):\n",
    "      epochResults = {}\n",
    "      for train_df in pd.read_csv(testCSVFile, chunksize=testChunkSize):\n",
    "        train_df = train_df.drop(columns=['NodeID'])\n",
    "        train_df = train_df.sample(frac=1).reset_index(drop=True)#shuffle\n",
    "\n",
    "        val_df = valReader.getChunk()\n",
    "        val_df = val_df.drop(columns=['NodeID'])\n",
    "        val_df = val_df.sample(frac=1).reset_index(drop=True)#shuffle\n",
    "\n",
    "        train_labels = np.array(train_df.pop('HasDetailedRoutingViolation'))\n",
    "        val_labels = np.array(val_df.pop('HasDetailedRoutingViolation'))\n",
    "\n",
    "        train_df = scaler.transform(train_df)\n",
    "        val_df = scaler.transform(val_df)\n",
    "\n",
    "        train_array = np.array(train_df)\n",
    "        val_array = np.array(val_df)\n",
    "\n",
    "        weight = None\n",
    "        if strategy == BalanceStrategy.OVERSAMPLE:\n",
    "          train_array, train_labels = oversample(train_array, train_labels)\n",
    "        elif strategy == BalanceStrategy.UNDERSAMPLE:\n",
    "          train_array, train_labels = undersample(train_array, train_labels)\n",
    "        elif strategy == BalanceStrategy.WEIGHTS:\n",
    "          weight = calculate_class_weights(train_labels)\n",
    "\n",
    "        timeStart = time.time()\n",
    "        train_history = model.fit(x=train_array,\n",
    "                                 y=train_labels,\n",
    "                                 batch_size=batch_size,\n",
    "                                 validation_data=(val_array, val_labels),\n",
    "                                 class_weight=weight)\n",
    "        timeEnd = time.time()\n",
    "\n",
    "        if len(epochResults) == 0:\n",
    "          epochResults = {x:[] for x in resultMetrics}\n",
    "        epochResults['TrainingRuntime'].append(timeEnd - timeStart)\n",
    "        for key, value in train_history.history.items():\n",
    "          epochResults[key].append(value[0])\n",
    "      # end chunk read iteration\n",
    "\n",
    "      finalResults['TrainingRuntime'].append(sum(epochResults['TrainingRuntime']))\n",
    "      for x in {'auc', 'loss', 'val_auc', 'val_loss'}:# AVG resultMetrics\n",
    "        finalResults[x].append(sum(epochResults[x]) / len(epochResults[x]))\n",
    "\n",
    "      tp = sum(epochResults['tp'])\n",
    "      fp = sum(epochResults['fp'])\n",
    "      tn = sum(epochResults['tn'])\n",
    "      fn = sum(epochResults['fn'])\n",
    "      precision, recall, accuracy, fscore, mcc = calculateMetrics(tp, fp, tn, fn)\n",
    "      finalResults['tp'].append(tp)\n",
    "      finalResults['fp'].append(fp)\n",
    "      finalResults['tn'].append(tn)\n",
    "      finalResults['fn'].append(fn)\n",
    "      finalResults['precision'].append(precision)\n",
    "      finalResults['recall'].append(recall)\n",
    "      finalResults['accuracy'].append(accuracy)\n",
    "      finalResults['fscore'].append(fscore)\n",
    "      finalResults['mcc'].append(mcc)\n",
    "\n",
    "      vtp = sum(epochResults['val_tp'])\n",
    "      vfp = sum(epochResults['val_fp'])\n",
    "      vtn = sum(epochResults['val_tn'])\n",
    "      vfn = sum(epochResults['val_fn'])\n",
    "      vprecision, vrecall, vaccuracy, vfscore, vmcc = calculateMetrics(vtp, vfp, vtn, vfn)\n",
    "      finalResults['val_tp'].append(vtp)\n",
    "      finalResults['val_fp'].append(vfp)\n",
    "      finalResults['val_tn'].append(vtn)\n",
    "      finalResults['val_fn'].append(vfn)\n",
    "      finalResults['val_precision'].append(vprecision)\n",
    "      finalResults['val_recall'].append(vrecall)\n",
    "      finalResults['val_accuracy'].append(vaccuracy)\n",
    "      finalResults['val_fscore'].append(vfscore)\n",
    "      finalResults['val_mcc'].append(vmcc)\n",
    "    # end Epoch\n",
    "    pd.DataFrame(finalResults).to_csv(modelPath+'/trainingResults.csv', index=False)\n",
    "    model.save(modelPath+'/model/savedModel')\n",
    "    model.save_weights(modelPath+'/modelWeights/model.ckpt')\n",
    "  # end all Epochs\n",
    "# end all Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21711b28",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9854a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSVs\n",
    "# Drop node IDS\n",
    "# Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c950647",
   "metadata": {},
   "source": [
    "# Generate Train and Test CSVs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba0a3f26",
   "metadata": {},
   "source": [
    "circuitsDir = '/home/sheiny/workspace/RoutedDesigns/'\n",
    "neighborDistance = 1\n",
    "testSize = 0.2 #20%\n",
    "useRandomOversample = False\n",
    "\n",
    "if os.path.exists('data/'):\n",
    "  shutil.rmtree('data/')\n",
    "  os.mkdir('data/')\n",
    "else:\n",
    "  os.mkdir('data/')\n",
    "\n",
    "typesOfDRVs = [\"AdjacentCutSpacing\", \"SameLayerCutSpacing\", \"EndOfLine\", \"FloatingPatch\", \"MinArea\", \"MinWidth\",\n",
    "  \"NonSuficientMetalOverlap\", \"CutShort\", \"MetalShort\", \"OutOfDieShort\", \"CornerSpacing\", \"ParallelRunLength\"]\n",
    "SelectedDRVTypes = [\"CutShort\", \"MetalShort\"]\n",
    "label_name = \"HasDetailedRoutingViolation\"\n",
    "\n",
    "circuits = []\n",
    "for circuit in os.listdir(circuitsDir):\n",
    "  if os.path.isdir(circuitsDir+'/'+circuit) and circuit != 'nangate45':\n",
    "    for file in os.listdir(circuitsDir+'/'+circuit+'/base/'):\n",
    "      if '_viol.csv' in file:\n",
    "        circuits.append(circuitsDir+circuit+'/base/'+file.split('_')[0])\n",
    "circuits.sort()\n",
    "\n",
    "testIdx = set(random.sample(list(range(len(circuits))), int(testSize*len(circuits))))\n",
    "testCircuits = [circuits[x] for x in testIdx]\n",
    "circuits = [n for i, n in enumerate(circuits) if i not in testIdx]\n",
    "circuits.sort()\n",
    "testCircuits.sort()\n",
    "\n",
    "with open('data/CSVInfo.txt', 'w') as fp:\n",
    "  fp.write('Train Circuits:\\n')\n",
    "  for circuit in circuits:\n",
    "    fp.write(circuit+'\\n')\n",
    "  fp.write('\\nTest Circuits:\\n')\n",
    "  for circuit in testCircuits:\n",
    "    fp.write(circuit+'\\n')\n",
    "  fp.close()\n",
    "\n",
    "def processCSV(csvPath):\n",
    "  typesOfDRVs = [\"AdjacentCutSpacing\", \"SameLayerCutSpacing\", \"EndOfLine\", \"FloatingPatch\", \"MinArea\", \"MinWidth\",\n",
    "  \"NonSuficientMetalOverlap\", \"CutShort\", \"MetalShort\", \"OutOfDieShort\", \"CornerSpacing\", \"ParallelRunLength\"]\n",
    "  SelectedDRVTypes = [\"CutShort\", \"MetalShort\"]\n",
    "\n",
    "  df = pd.read_csv(csvPath, dtype=np.float32)\n",
    "  df[\"HasDetailedRoutingViolation\"] = False\n",
    "  for drv in SelectedDRVTypes:\n",
    "    df[\"HasDetailedRoutingViolation\"] = df[label_name] | df[drv]\n",
    "  df = df.drop(columns=typesOfDRVs)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51f21911",
   "metadata": {},
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "saveHeader = True\n",
    "for i in range(len(circuits)):\n",
    "  if i % 10 == 0:\n",
    "    print('reading: ',i,' of ', len(circuits), ' circuits.')\n",
    "  circuit = circuits[i]\n",
    "\n",
    "  tempDF = processCSV(circuit+'_1_nonViol.csv')\n",
    "  if useRandomOversample:\n",
    "    tempDF = tempDF.sample(frac=0.1, replace=False)\n",
    "  if len(tempDF) != 0:\n",
    "    scaler.partial_fit(tempDF.drop(columns=['NodeID', 'HasDetailedRoutingViolation']))\n",
    "  valDF = tempDF.sample(frac=0.2)\n",
    "  tempDF = tempDF.drop(valDF.index)\n",
    "  valDF.to_csv('data/validation.csv', mode='a', index=False, header=saveHeader) \n",
    "  tempDF.to_csv('data/train.csv', mode='a', index=False, header=saveHeader)\n",
    "  saveHeader = False\n",
    "\n",
    "  tempDF = processCSV(circuit+'_1_surround.csv')\n",
    "  if len(tempDF) != 0:\n",
    "    scaler.partial_fit(tempDF.drop(columns=['NodeID', 'HasDetailedRoutingViolation']))\n",
    "  valDF = tempDF.sample(frac=0.2)\n",
    "  tempDF = tempDF.drop(valDF.index)\n",
    "  valDF.to_csv('data/validation.csv', mode='a', index=False, header=False) \n",
    "\n",
    "  tempDF = processCSV(circuit+'_1_viol.csv')\n",
    "  if len(tempDF) != 0:\n",
    "    scaler.partial_fit(tempDF.drop(columns=['NodeID', 'HasDetailedRoutingViolation']))\n",
    "  valDF = tempDF.sample(frac=0.2)\n",
    "  tempDF = tempDF.drop(valDF.index)\n",
    "  valDF.to_csv('data/validation.csv', mode='a', index=False, header=False) \n",
    "  tempDF.to_csv('data/train.csv', mode='a', index=False, header=False)\n",
    "\n",
    "pickle.dump(scaler, open('data/scaler.pkl','wb'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b000ca2a",
   "metadata": {},
   "source": [
    "saveHeader = True\n",
    "for i in range(len(testCircuits)):\n",
    "  if i % 10 == 0:\n",
    "    print('reading: ',i,' of ', len(testCircuits), ' circuits.')\n",
    "  circuit = testCircuits[i]\n",
    "  processCSV(circuit+'_1_nonViol.csv').to_csv('data/test.csv', mode='a', index=False, header=saveHeader)\n",
    "  saveHeader = False\n",
    "  processCSV(circuit+'_1_surround.csv').to_csv('data/test.csv', mode='a', index=False, header=False)\n",
    "  processCSV(circuit+'_1_viol.csv').to_csv('data/test.csv', mode='a', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
