{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb56f37",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7846cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 17:16:28.398669: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-05 17:16:29.040137: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-05 17:16:29.040216: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-05 17:16:29.040224: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "from enum import Enum\n",
    "import imblearn\n",
    "import time\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# https://towardsdatascience.com/still-saving-your-data-in-csv-try-these-other-options-9abe8b83db3a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea80aed",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d8209cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCNNModel(evalMetrics, learningRate, inputSize):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = inputSize))\n",
    "  model.add(tf.keras.layers.AveragePooling2D((3, 3)))\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "  model.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics = evalMetrics)\n",
    "  return model\n",
    "\n",
    "def calculateMetrics(tp, fp, tn, fn):\n",
    "  if tp == 0: #meaningless performance (always predict no viol or there is no viol in labels)\n",
    "    return 0, 0, 0, 0, -1 #return precision, recall, accuracy, fscore, mcc\n",
    "  precision = tp/(tp + fp)\n",
    "  recall = tp/(tp + fn)\n",
    "  accuracy = (tp + tn)/(tp + fn + tn + fp)\n",
    "  fscore = (2 * precision * recall)/(precision + recall)\n",
    "  sqrt = math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "  mcc = -1\n",
    "  if sqrt != 0:\n",
    "    mcc = ((tp * tn) - (fp * fn))/sqrt\n",
    "  return precision, recall, accuracy, fscore, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22963d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/CSV/bp/cts_bp_80_viol.csv', dtype=np.float32, header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e54192",
   "metadata": {},
   "source": [
    "# Traning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1000fc58",
   "metadata": {},
   "source": [
    "batch_size = 32 # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "numEpochs = 100\n",
    "# https://www.youtube.com/watch?v=DO-xv9WLvoM\n",
    "# https://towardsdatascience.com/how-to-optimize-learning-rate-with-tensorflow-its-easier-than-you-think-164f980a7c7b\n",
    "learningRate = 0.001 #Eh?Predictor=0.05, default=0.001\n",
    "dropOut = 0.05 #Eh?Predictor=0.05\n",
    "evalMetrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "               tf.keras.metrics.FalsePositives(name='fp'),\n",
    "               tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "               tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall'),\n",
    "               tf.keras.metrics.AUC(name='auc')]\n",
    "testChunkSize = 1e5 # 1e6 ~= 10 iterations to cover whole train dataset\n",
    "validationChunkSize = int(testChunkSize * 0.2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# scaler = sklearn.preprocessing.StandardScaler()\n",
    "inputSize = (22, 33, 33)\n",
    "\n",
    "model = makeCNNModel(evalMetrics, dropOut, learningRate, inputSize)\n",
    "\n",
    "dfViol = pd.read_csv('CNNdata/aes_viol.csv', header=None)\n",
    "dfViolVal = dfViol.sample(frac=0.2)\n",
    "dfViol = dfViol.drop(dfViolVal.index)\n",
    "\n",
    "dfSurround = pd.read_csv('CNNdata/aes_surround.csv', header=None)\n",
    "dfSurroundVal = dfSurround.sample(frac=0.1)\n",
    "dfSurround = dfSurround.drop(dfSurroundVal.index)\n",
    "\n",
    "dfNonViol = pd.read_csv('CNNdata/aes_nonViol.csv', header=None)\n",
    "\n",
    "df = pd.concat([dfViol, dfSurround, dfNonViol], ignore_index=True)\n",
    "valDf = pd.concat([dfViolVal, dfSurroundVal], ignore_index=True)\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "valDf = valDf.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "labels = df.pop(df.columns.values[-1])\n",
    "valLabels = valDf.pop(valDf.columns.values[-1])\n",
    "\n",
    "trainHyperImages = np.array(df).reshape(len(df),22,33,33)\n",
    "valHyperImages = np.array(valDf).reshape(len(valDf),22,33,33)\n",
    "\n",
    "train_history = model.fit(x=trainHyperImages,\n",
    "                         y=labels,\n",
    "                         batch_size=batch_size,\n",
    "                         validation_data=(valHyperImages, valLabels),\n",
    "                         epochs=numEpochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c950647",
   "metadata": {},
   "source": [
    "# Generate Train and Test CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f9c7ea",
   "metadata": {},
   "source": [
    "allCircuits = ['/data/Pickle/'+x+'/' for x in os.listdir('/data/Pickle/')]\n",
    "allCSVs = list()\n",
    "for circuit in allCircuits:\n",
    "  for file in os.listdir(circuit):\n",
    "    if '.pkl' in file:\n",
    "      continue\n",
    "    allCSVs.append(circuit+file)\n",
    "\n",
    "trainingCircuits = ['/data/Pickle/aes/', '/data/Pickle/jpeg/', '/data/Pickle/tinyRocket/',\n",
    "  '/data/Pickle/bp/', '/data/Pickle/ibex/', '/data/Pickle/dynamic_node/',\n",
    "  '/data/Pickle/bp_be/', '/data/Pickle/bp_fe/', '/data/Pickle/bp_multi/', '/data/Pickle/gcd/']\n",
    "validationCircuits = ['/data/Pickle/swerv/']\n",
    "testCircuits = ['/data/Pickle/swerv_wrapper/']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4b8cff6",
   "metadata": {},
   "source": [
    "# Split files and compress from CSV to pickle format\n",
    "readChunkSize = 20000\n",
    "# readChunkSize = 100000 #TODO also try 100k\n",
    "\n",
    "for csv in allCSVs:\n",
    "  print('reading ', csv)\n",
    "  i=0\n",
    "  for df in pd.read_csv(csv, dtype=np.float32, header=None, chunksize=readChunkSize):\n",
    "    df.to_pickle(csv[:csv.find(\".\")]+'_'+str(i)+'.pkl', compression='gzip')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c663877",
   "metadata": {},
   "source": [
    "# Init scaler\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "for circuit in trainingCircuits:\n",
    "  for pkl in os.listdir(circuit):\n",
    "    if '.pkl' not in pkl:\n",
    "      continue\n",
    "    print('reading ', circuit+pkl)\n",
    "    df = pd.read_pickle(circuit+pkl, compression='gzip')\n",
    "    scaler.partial_fit(df.iloc[:, : 33*33*22])\n",
    "pickle.dump(scaler, open('/data/scaler.pkl','wb'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69601c5e",
   "metadata": {},
   "source": [
    "# Scale all pickles and overwrite them\n",
    "scaler = pickle.load(open('/data/scaler.pkl','rb'))\n",
    "for circuit in allCircuits:\n",
    "  for pkl in os.listdir(circuit):\n",
    "    if '.pkl' not in pkl:\n",
    "      continue\n",
    "    print('reading', circuit+pkl)\n",
    "    df = pd.read_pickle(circuit+pkl, compression='gzip')\n",
    "    df.iloc[:, : 33*33*22] = scaler.transform(df.iloc[:, : 33*33*22]).round(decimals=2)\n",
    "    df.to_pickle(circuit+pkl, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingCircuits = ['/data/Pickle/aes/', '/data/Pickle/jpeg/', '/data/Pickle/tinyRocket/',\n",
    "  '/data/Pickle/bp/', '/data/Pickle/ibex/', '/data/Pickle/dynamic_node/',\n",
    "  '/data/Pickle/bp_be/', '/data/Pickle/bp_fe/', '/data/Pickle/bp_multi/', '/data/Pickle/gcd/', '/data/Pickle/swerv/']\n",
    "\n",
    "numEpochs = 100\n",
    "inputSize = (22, 33, 33)\n",
    "learningRate = 0.005\n",
    "batchSize = 32\n",
    "evalMetrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "               tf.keras.metrics.FalsePositives(name='fp'),\n",
    "               tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "               tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall'),\n",
    "               tf.keras.metrics.AUC(name='auc')]\n",
    "model = makeCNNModel(evalMetrics, learningRate, inputSize)\n",
    "\n",
    "trainingPickles = list()\n",
    "for circuit in trainingCircuits:\n",
    "  for pkl in os.listdir(circuit):\n",
    "    if '.pkl' not in pkl:\n",
    "      continue\n",
    "    trainingPickles.append(circuit+pkl)\n",
    "trainingPickles.sort()\n",
    "\n",
    "historyDf = pd.DataFrame()\n",
    "for epoch in range(numEpochs):\n",
    "  random.shuffle(trainingPickles)\n",
    "  train = trainingPickles\n",
    "  for trainPickle in trainingPickles:\n",
    "    trainDf = pd.read_pickle(trainPickle, compression='gzip')\n",
    "    valDf = trainDf.sample(frac=0.2)\n",
    "    trainDf = trainDf.drop(valDf.index)\n",
    "\n",
    "    \n",
    "    labels = trainDf.pop(trainDf.columns.values[-1])\n",
    "    valLabels = valDf.pop(valDf.columns.values[-1])\n",
    "    print('labels', sum(labels), 'valLabels', sum(valLabels))\n",
    "    trainHyperImages = np.array(trainDf).reshape(len(trainDf),22,33,33)\n",
    "    valHyperImages = np.array(valDf).reshape(len(valDf),22,33,33)\n",
    "    train_history = model.fit(x=trainHyperImages,\n",
    "                             y=labels,\n",
    "                             batch_size=batchSize,\n",
    "                             validation_data=(valHyperImages, valLabels))\n",
    "    history = pd.DataFrame(train_history.history)\n",
    "    historyDf = pd.concat([historyDf, history])\n",
    "    historyDf.to_csv('model/history.csv', index=False)\n",
    "  model.save('model/savedModel')\n",
    "  model.save_weights('model/modelWeights/model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
