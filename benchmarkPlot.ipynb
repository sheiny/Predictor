{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e3a2b8",
   "metadata": {},
   "source": [
    "# Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f04caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/\n",
    "https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right\n",
    "\n",
    "a figura com drvs justifica muito bem a escolha de 80% para teste\n",
    "\n",
    "\n",
    "fazer eval em todos dfs de 80%, adicionar epoch e indices etc para depois pegar caso necessario\n",
    "pegar melhor modelo olhando o loss e aplicar pra todos circuitos de teste fcn, ou fcn_large\n",
    "\n",
    "\n",
    "\n",
    "Figura:\n",
    "como alguem faria para usar o preditor\n",
    "como alguem faria para testar com outra tecnologia o preditor\n",
    "explicar que ele he independente de tecnologia\n",
    "fluxograma mostrando a parte do ORDF e a parte do INNOVUS para geracao dos benchamrks\n",
    "dps para geracao dos dados de treino e inferencia.\n",
    "Explicar o problema dos dados, não é só uma questão de armazenamento, mas a leitura deles\n",
    "tbm seria muito demorada inviabilizando o treino do modelo.\n",
    "justificar o porque de pegar soh short"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb56f37",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9021c96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c1dc8",
   "metadata": {},
   "source": [
    "# Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training performace\n",
    "# trainResultDF = pickle.load(open('cnn/trainResultDF.pkl', 'rb'))\n",
    "trainResultDF = pickle.load(open('fcn/trainResultDF.pkl', 'rb'))\n",
    "epochs = {x for x in trainResultDF['epoch']}\n",
    "print('epoch, tp, tn, fp, fn')\n",
    "for x in range(len(epochs)):\n",
    "  epochDF = trainResultDF.loc[trainResultDF['epoch'] == x]\n",
    "  print(x, epochDF['tp'].sum(), epochDF['tn'].sum(), epochDF['fp'].sum(), epochDF['fn'].sum(), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training metrics for a given design\n",
    "# TODO: Maybe change this to take the average for all types of the same design\n",
    "trainResultDF = pickle.load(open('fcn/trainResultDF.pkl', 'rb'))\n",
    "design = 'swerv_84'\n",
    "sortedDF = trainResultDF.loc[trainResultDF['design'] == design].sort_values(by=['epoch'])\n",
    "ytrain = [x for x in sortedDF['tp']]\n",
    "yval = [x for x in sortedDF['tn']]\n",
    "plt.plot(ytrain, label = \"tp\")\n",
    "plt.plot(yval, label = \"tn\")\n",
    "plt.legend()\n",
    "plt.title(design)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9fc59e",
   "metadata": {},
   "source": [
    "# Cross Validation Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a420673",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossValResultDF = pickle.load(open('fcnCV18.pkl', 'rb'))\n",
    "rows = []\n",
    "for index, row in crossValResultDF.iterrows():\n",
    "  tp = row['tp']\n",
    "  tn = row['tn']\n",
    "  fp = row['fp']\n",
    "  fn = row['fn']\n",
    "  precision = tp/(tp + fp)\n",
    "  recall = tp/(tp + fn)\n",
    "  TotalPos = tp+fn\n",
    "  TotalNeg = fp+tn\n",
    "  PosRatio = ((tp+fn)/(tp+fn+fp+tn))*100\n",
    "  tpr = tp/(tp+fn)\n",
    "  spc = tn/(tn+fp)\n",
    "  fa = fp/(tn+fp)\n",
    "  acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "  sqrt = math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "  mcc = 0\n",
    "  if sqrt != 0:\n",
    "    mcc = ((tp * tn) - (fp * fn))/sqrt\n",
    "  rows.append({'tp':tp, 'tn':tn, 'fp':fp, 'fn':fn,\n",
    "               'PosRatio%':PosRatio,\n",
    "               'tpr':tpr, 'spc':spc, 'acc':acc, 'MCC[-1:1]':mcc})\n",
    "  print()\n",
    "\n",
    "\n",
    "crossValResultDF = pd.DataFrame(rows, index=crossValResultDF['Design'])\n",
    "crossValResultDF.loc['mean'] = crossValResultDF.mean()\n",
    "# crossValResultDF.to_csv('fcnCV18.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6d418c",
   "metadata": {},
   "source": [
    "# Benchmark Information Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19541ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('benchmark.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a92600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot Routing Runtime Break Down\n",
    "dfRuntime = df.loc[df['Design'].str.contains('80')].sort_values(by=['COMPONENTS'], ascending=False)\n",
    "dfRuntime['Design'] = [x[0:x.rfind('_')] for x in dfRuntime['Design']]\n",
    "dfRuntime = dfRuntime.set_index('Design')\n",
    "numIDRShorts = dfRuntime['IDRShort']\n",
    "dfRuntime = dfRuntime[['GR', 'IDR', 'FDR']]\n",
    "ax = dfRuntime.plot.bar(stacked=True)\n",
    "\n",
    "numBars = int(len(ax.patches)/3)\n",
    "for rect, value in zip(ax.patches[numBars:numBars*2], numIDRShorts):\n",
    "  h = rect.get_height() /2.\n",
    "  w = rect.get_width() /2.\n",
    "  x, y = rect.get_xy()\n",
    "  ax.text(x+w, y+h, value, horizontalalignment='center',verticalalignment='center')\n",
    "\n",
    "ax.set_ylabel('Runtime in seconds')\n",
    "ax.set_xlabel('Designs (80% row utilization)')\n",
    "ax.legend([\"Global Routing\", \"Initial Detailed Routing\", \"Complete Detailed Routing\"])\n",
    "plt.title('Routing Runtime Break Down For 80% Row Utilization Designs')\n",
    "# plt.savefig('routing_runtime.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg IDR short (considering full routed circuits only)\n",
    "idrShort = []\n",
    "for x in range(70, 91):\n",
    "  tempDf = df.loc[df['Design'].str.contains(str(x))]\n",
    "  tempDf = tempDf.loc[tempDf['FDRTotal'] == 0]\n",
    "  avgIDRShort = sum(tempDf['IDRShort']/len(tempDf))\n",
    "  idrShort.append(avgIDRShort)\n",
    "    \n",
    "plt.plot([y for y in range(70, 91)], idrShort, color = 'r')\n",
    "plt.xlabel(\"Design Density (Row Utilization %)\")\n",
    "plt.ylabel(\"Initial Detailed Routing Short Violations (IDRV)\")\n",
    "plt.title('Average IDR Short x Row Utilization (Only fully routable circuits)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0532a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg IDR short (considering full routed circuits only)\n",
    "fdrRuntime = []\n",
    "for x in range(70, 91):\n",
    "  tempDf = df.loc[df['Design'].str.contains(str(x))]\n",
    "  tempDf = tempDf.loc[tempDf['FDRTotal'] == 0]\n",
    "  fdr = sum(tempDf['FDR']/len(tempDf))\n",
    "  fdrRuntime.append(fdr)\n",
    "\n",
    "plt.plot([y for y in range(70, 91)], fdrRuntime, color = 'r')\n",
    "plt.xlabel(\"Design Density (Row Utilization %)\")\n",
    "plt.ylabel(\"Runtime (seconds)\")\n",
    "plt.title('Average Runtime to complete routing (Only fully routable circuits)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
