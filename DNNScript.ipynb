{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1cbd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Imports ##########\n",
    "import json\n",
    "import math\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shutil\n",
    "from keras.callbacks import CSVLogger\n",
    "import os\n",
    "from enum import Enum\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ab8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Hyper parameters ##########\n",
    "class BalanceStrategy(Enum):\n",
    "    NONE = 0\n",
    "    WEIGHTS = 1\n",
    "    OVERSAMPLE = 2\n",
    "    UNDERSAMPLE = 3\n",
    "\n",
    "########## Data PreProcessig Algorithms ##########\n",
    "# The features will be rescaled so that they’ll have the properties of a standard normal distribution.\n",
    "# mean (μ) = 0\n",
    "# standard deviation (σ) = 1\n",
    "def standardize(train_array, val_array, test_array=None):\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    train_array = scaler.fit_transform(train_array)\n",
    "    val_array = scaler.transform(val_array)\n",
    "    if test_array is not None:\n",
    "        test_array = scaler.transform(test_array)\n",
    "        return train_array, val_array, test_array\n",
    "    return train_array, val_array\n",
    "\n",
    "def print_positive_ratio(train_labels):\n",
    "    neg, pos = np.bincount(train_labels)\n",
    "    total = neg + pos\n",
    "    print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))\n",
    "\n",
    "# Claculate weight for classes\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "def calculate_class_weights(df, train_labels):\n",
    "    neg, pos = np.bincount(train_labels)\n",
    "    total = neg + pos\n",
    "    weight_for_0 = (1 / neg)*(total)/2.0 \n",
    "    weight_for_1 = (1 / pos)*(total)/2.0\n",
    "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "    print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "    print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
    "    return class_weight, neg, pos\n",
    "\n",
    "def oversample(train_array, train_labels):\n",
    "    oversample = RandomOverSampler()\n",
    "    train_array, train_labels = oversample.fit_resample(train_array, train_labels)\n",
    "    return train_array, train_labels\n",
    "\n",
    "def undersample(train_array, train_labels):\n",
    "    undersample = RandomUnderSampler()\n",
    "    train_array, train_labels = undersample.fit_resample(train_array, train_labels)\n",
    "    return train_array, train_labels\n",
    "\n",
    "\n",
    "########## Load Training Data ##########\n",
    "def loadDataFrames(training_csvs, test_csvs, strategy, allDRVTypes):\n",
    "#     dataframes = [pd.read_csv(csv) for csv in training_csvs]\n",
    "#     test_dataframes = [pd.read_csv(test_csv) for test_csv in test_csvs]\n",
    "    dataframes = [pd.read_csv(csv, dtype=np.float32) for csv in training_csvs]\n",
    "    test_dataframes = [pd.read_csv(test_csv, dtype=np.float32) for test_csv in test_csvs]\n",
    "        \n",
    "    #merge all DataFrames into a single one\n",
    "    df = pd.concat(dataframes, ignore_index=True)\n",
    "    test_df = pd.concat(test_dataframes, ignore_index=True)\n",
    "    del dataframes #save some memory\n",
    "    del test_dataframes #save some memory\n",
    "\n",
    "    # Remove NodeIDs (debug info)\n",
    "    df = df.drop(columns=[\"NodeID\"])\n",
    "    test_df_NodeID = test_df[\"NodeID\"] #backup this for DRV draw\n",
    "    test_df = test_df.drop(columns=[\"NodeID\"])\n",
    "\n",
    "    # Make sure to clear all DRV columns\n",
    "    df[label_name] = False\n",
    "    test_df[label_name] = False\n",
    "    # Apply filter for selected DRVs\n",
    "    for drv in SelectedDRVTypes:\n",
    "        df[label_name] = df[label_name] | df[drv]\n",
    "        test_df[label_name] = test_df[label_name] | test_df[drv]\n",
    "\n",
    "    # Drop all drv collumns because they are no longer necessary\n",
    "    df = df.drop(columns=allDRVTypes)\n",
    "    test_df = test_df.drop(columns=allDRVTypes)\n",
    "\n",
    "    # Split 80/20 (train 80% test 20%)\n",
    "    train_df, val_df = sklearn.model_selection.train_test_split(df, test_size=0.2)\n",
    "\n",
    "    # Build np arrays of labels and features.\n",
    "    train_labels = np.array(train_df.pop(label_name))\n",
    "    val_labels = np.array(val_df.pop(label_name))\n",
    "    test_labels = np.array(test_df.pop(label_name))\n",
    "    train_array = np.array(train_df)\n",
    "    val_array = np.array(val_df)\n",
    "    test_array = np.array(test_df)\n",
    "\n",
    "    # Save some memory\n",
    "    del train_df\n",
    "    del test_df\n",
    "    del val_df\n",
    "\n",
    "    # Apply the selected strategy to handle umbalanced data.\n",
    "    weight = None\n",
    "    if strategy == BalanceStrategy.OVERSAMPLE:\n",
    "        train_array, train_labels = oversample(train_array, train_labels)\n",
    "    elif strategy == BalanceStrategy.UNDERSAMPLE:\n",
    "        train_array, train_labels = undersample(train_array, train_labels)\n",
    "    elif strategy == BalanceStrategy.WEIGHTS:\n",
    "        weight = calculate_class_weights(df, train_labels)\n",
    "        weight = weight[0]\n",
    "\n",
    "    print_positive_ratio(train_labels)\n",
    "\n",
    "    del df # Save some memory\n",
    "\n",
    "    # Scale\n",
    "    train_array, val_array, test_array = standardize(train_array, val_array, test_array)\n",
    "    return train_array, val_array, test_array, train_labels, val_labels, test_labels, weight\n",
    "\n",
    "\n",
    "########## Learning Model ##########\n",
    "def make_model(evalMetrics, dropOut, learningRate, inputSize, numNodes, numLayers, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=inputSize))\n",
    "    for x in range(numLayers):\n",
    "        model.add(tf.keras.layers.Dense(numNodes, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(dropOut))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learningRate),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=evalMetrics)\n",
    "    return model\n",
    "\n",
    "\n",
    "########## Test and check Performance ##########\n",
    "def calculate_test_metrics(model, results):\n",
    "    m = {}\n",
    "    for name, value in zip(model.metrics_names, results):\n",
    "        m[name] = value\n",
    "    if m['precision'] + m['recall'] != 0:\n",
    "        f_score = 2 * ((m['precision'] * m['recall'])/(m['precision'] + m['recall']))\n",
    "        m['F-score'] = f_score\n",
    "    sqrt = math.sqrt((m['tp']+m['fp'])*(m['tp']+m['fn'])*(m['tn']+m['fp'])*(m['tn']+m['fn']))\n",
    "    if sqrt != 0:\n",
    "        mcc = ((m['tp'] * m['tn']) - (m['fp'] * m['fn']))/sqrt\n",
    "        m['MCC'] = mcc\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbba92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Hyper Parameters ##########\n",
    "typesOfDRVs = [\"AdjacentCutSpacing\", \"SameLayerCutSpacing\", \"EndOfLine\", \"FloatingPatch\", \"MinArea\", \"MinWidth\",\n",
    "  \"NonSuficientMetalOverlap\", \"CutShort\", \"MetalShort\", \"OutOfDieShort\", \"CornerSpacing\", \"ParallelRunLength\"]\n",
    "SelectedDRVTypes = [\"CutShort\", \"MetalShort\"]\n",
    "label_name = \"HasDetailedRoutingViolation\"\n",
    "designs_path = '/home/sheiny/workspace/RoutedDesigns/'\n",
    "neighborhoodSize = str(0)\n",
    "circuits = [x for x in os.listdir(designs_path) if '.' not in x and 'nangate45' not in x]\n",
    "\n",
    "test_csv_list = []\n",
    "for circuit in circuits:\n",
    "    files = os.listdir(designs_path+circuit+'/base/')\n",
    "    csvs = []\n",
    "    for file in files:\n",
    "        if neighborhoodSize+'.csv' not in file:\n",
    "            continue\n",
    "        csvs.append(file)\n",
    "    csvs.sort()\n",
    "    n = len(csvs)\n",
    "    middle = int(n/2)-1 if (n % 2 == 0 ) else int(n/2)\n",
    "    test_csv_list.append(designs_path+circuit+'/base/'+csvs[middle])\n",
    "\n",
    "csv_list = []\n",
    "for circuit in circuits:\n",
    "    files = os.listdir(designs_path+circuit+'/base/')\n",
    "    for file in files:\n",
    "        if neighborhoodSize+'.csv' not in file:\n",
    "            continue\n",
    "        csvFile = designs_path+circuit+'/base/'+file\n",
    "        if csvFile not in test_csv_list:\n",
    "            csv_list.append(designs_path+circuit+'/base/'+file)\n",
    "\n",
    "\n",
    "batch_size = 32 # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "epochs = 10\n",
    "learningRate = 0.001 #Eh?Predictor=0.05, default=0.001\n",
    "dropOut = 0.05 #Eh?Predictor=0.05\n",
    "evalMetrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "               tf.keras.metrics.FalsePositives(name='fp'),\n",
    "               tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "               tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall'),\n",
    "               tf.keras.metrics.AUC(name='auc')]\n",
    "\n",
    "\n",
    "\n",
    "for strategy in [BalanceStrategy.NONE]:\n",
    "    strat = str(strategy).split('.')[1]\n",
    "    for numNodes in [50]:\n",
    "        #for numLayers in range(1,5):\n",
    "        for numLayers in [1]:\n",
    "            model_name = strat+'_'+str(numLayers)+'_'+str(numNodes)+'_Epochs'+str(epochs)\n",
    "            print(model_name)\n",
    "        \n",
    "            ########## Load Data ##########\n",
    "            train_array, val_array, test_array, train_labels, val_labels, test_labels, weight = loadDataFrames(csv_list, test_csv_list, strategy, typesOfDRVs)\n",
    "\n",
    "\n",
    "            ########## Training ##########\n",
    "            if os.path.exists(model_name):\n",
    "                shutil.rmtree(model_name)\n",
    "            else:\n",
    "                os.mkdir(model_name)\n",
    "            checkpoint_path = model_name+\"/cp.ckpt\"\n",
    "\n",
    "            # Create a callback that saves the model's weights at the end of each epoch\n",
    "            cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True)\n",
    "            # Create a callback that saves model history at the end of each epoch\n",
    "            csv_logger = CSVLogger(model_name+\"/model_history_log.csv\", append=True)\n",
    "\n",
    "            #initialize learning model\n",
    "            neg, pos = np.bincount(train_labels)\n",
    "            initial_bias = np.log([pos/neg])\n",
    "\n",
    "            inputSize = len(train_array[0])\n",
    "            model = make_model(evalMetrics, dropOut, learningRate, inputSize, numNodes, numLayers, initial_bias)\n",
    "\n",
    "            dataset = tf.data.Dataset.from_tensor_slices((train_array, train_labels))\n",
    "            train_dataset = dataset.shuffle(len(train_array)).batch(batch_size)\n",
    "\n",
    "            train_history = model.fit(train_dataset,\n",
    "                                      batch_size=batch_size,\n",
    "                                      validation_data=(val_array, val_labels),\n",
    "                                      class_weight=weight, #default class_weight = None\n",
    "                                      epochs=epochs,\n",
    "                                      callbacks=[cp_callback, csv_logger])\n",
    "\n",
    "\n",
    "            ########## Test ##########\n",
    "            baseline_results = model.evaluate(test_array,\n",
    "                                              test_labels,\n",
    "                                              batch_size=batch_size,\n",
    "                                              verbose=0)\n",
    "            test_metrics = calculate_test_metrics(model, baseline_results)\n",
    "            print(test_metrics)\n",
    "            with open(model_name+'/test_metrics.pkl', 'wb') as f:\n",
    "                pickle.dump(test_metrics, f)\n",
    "\n",
    "print('The END')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
