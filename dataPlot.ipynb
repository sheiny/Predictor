{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e3a2b8",
   "metadata": {},
   "source": [
    "# Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f04caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/\n",
    "https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right\n",
    "\n",
    "a figura com drvs justifica muito bem a escolha de 80% para teste\n",
    "\n",
    "\n",
    "fazer eval em todos dfs de 80%, adicionar epoch e indices etc para depois pegar caso necessario\n",
    "pegar melhor modelo olhando o loss e aplicar pra todos circuitos de teste fcn, ou fcn_large\n",
    "\n",
    "\n",
    "\n",
    "Figura:\n",
    "como alguem faria para usar o preditor\n",
    "como alguem faria para testar com outra tecnologia o preditor\n",
    "explicar que ele he independente de tecnologia\n",
    "fluxograma mostrando a parte do ORDF e a parte do INNOVUS para geracao dos benchamrks\n",
    "dps para geracao dos dados de treino e inferencia.\n",
    "Explicar o problema dos dados, não é só uma questão de armazenamento, mas a leitura deles\n",
    "tbm seria muito demorada inviabilizando o treino do modelo.\n",
    "justificar o porque de pegar soh short"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb56f37",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9021c96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c1dc8",
   "metadata": {},
   "source": [
    "# Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training performace\n",
    "trainResultDF = pickle.load(open('results/fcn/trainResultDF.pkl', 'rb'))\n",
    "epochs = {x for x in trainResultDF['epoch']}\n",
    "print('epoch, tp, tn, fp, fn')\n",
    "for x in range(len(epochs)):\n",
    "  epochDF = trainResultDF.loc[trainResultDF['epoch'] == x]\n",
    "  print(x, epochDF['tp'].sum(), epochDF['tn'].sum(), epochDF['fp'].sum(), epochDF['fn'].sum(), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training metrics for a given design\n",
    "# TODO: Maybe change this to take the average for all types of the same design\n",
    "trainResultDF = pickle.load(open('results/fcn/trainResultDF.pkl', 'rb'))\n",
    "design = 'aes_81'\n",
    "sortedDF = trainResultDF.loc[trainResultDF['design'] == design].sort_values(by=['epoch'])\n",
    "ytrain = [x for x in sortedDF['tp']]\n",
    "yval = [x for x in sortedDF['tn']]\n",
    "plt.plot(ytrain, label = \"tp\")\n",
    "plt.plot(yval, label = \"tn\")\n",
    "plt.legend()\n",
    "plt.title(design)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9fc59e",
   "metadata": {},
   "source": [
    "# Cross Validation Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a420673",
   "metadata": {},
   "outputs": [],
   "source": [
    "pklFile = 'results/cv/fcnCV50.pkl'\n",
    "\n",
    "crossValResultDF = pickle.load(open(pklFile, 'rb'))\n",
    "rows = []\n",
    "for index, row in crossValResultDF.iterrows():\n",
    "  tp = row['tp']\n",
    "  tn = row['tn']\n",
    "  fp = row['fp']\n",
    "  fn = row['fn']\n",
    "  precision = tp/(tp + fp)\n",
    "  recall = tp/(tp + fn)\n",
    "  TotalPos = tp+fn\n",
    "  TotalNeg = fp+tn\n",
    "  PosRatio = ((tp+fn)/(tp+fn+fp+tn))*100\n",
    "  tpr = tp/(tp+fn)\n",
    "  spc = tn/(tn+fp)\n",
    "  fa = fp/(tn+fp)\n",
    "  acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "  sqrt = math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "  mcc = 0\n",
    "  if sqrt != 0:\n",
    "    mcc = ((tp * tn) - (fp * fn))/sqrt\n",
    "  rows.append({'tp':tp, 'tn':tn, 'fp':fp, 'fn':fn,\n",
    "               'PosRatio%':PosRatio,\n",
    "               'tpr':tpr, 'spc':spc, 'acc':acc, 'MCC[-1:1]':mcc})\n",
    "  print()\n",
    "\n",
    "\n",
    "crossValResultDF = pd.DataFrame(rows, index=crossValResultDF['Design'])\n",
    "crossValResultDF.loc['mean'] = crossValResultDF.mean()\n",
    "crossValResultDF.to_csv(pklFile[:pklFile.find('.')]+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7dd163",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open('results/fcn/trainResultDF.pkl', 'rb'))\n",
    "df.to_csv('fcnTranining.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710e3747",
   "metadata": {},
   "source": [
    "# Prediction Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f458fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = '/data/CSVWhole/aes/'\n",
    "modelPath = 'results/fcn/model_18.pkl'\n",
    "outFile = 'predictions/aesFCN18Predictions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bf4322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, pkl):\n",
    "  testDf = pd.read_pickle(pkl, compression='zip')\n",
    "  labels = testDf.pop(testDf.columns.values[-1])\n",
    "  nodeIDs = testDf.pop(testDf.columns.values[0])#drop first column which contains the nodeIds\n",
    "  testHyperImages = np.array(testDf).reshape(len(testDf),22,33,33)\n",
    "  predictions = model.predict(testHyperImages)\n",
    "  return nodeIDs, predictions\n",
    "\n",
    "model = pickle.load(open(modelPath, 'rb'))\n",
    "pkls = [design+x for x in os.listdir(design) if '.pkl' in x]\n",
    "pkls.sort(key = lambda x : int(x[x.rfind('_')+1:x.find('.')]))\n",
    "results = []\n",
    "for pkl in pkls:\n",
    "  results.append(predict(model, pkl))\n",
    "toPrint = []\n",
    "for x, y in results:\n",
    "  pred = y > 0.5\n",
    "  for nodeID, viol in zip(x, pred):\n",
    "    if viol:\n",
    "      toPrint.append(int(nodeID))\n",
    "with open(outFile, 'w') as fp:\n",
    "  for node in toPrint:\n",
    "    fp.write(str(node)+'\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6d418c",
   "metadata": {},
   "source": [
    "# Benchmark Information Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19541ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beware the number of components is wrong!!! It is considering filler cells\n",
    "df = pd.read_pickle('benchmarkInfo/benchmark.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4746e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Info\n",
    "benchmarkDf = df.loc[df['Design'].str.contains('80')]\n",
    "columnsToDrop = ['SPECIALNETS','IDRShort', 'IDRTotal', 'FDRShort', 'FDRTotal', 'GR', 'IDR', 'FDR']\n",
    "benchmarkDf = benchmarkDf.drop(columns=columnsToDrop)\n",
    "benchmarkDf.sort_values(by=['COMPONENTS'], ascending=False)\n",
    "benchmarkDf.to_csv('benchmarkDf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a92600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot Routing Runtime Break Down\n",
    "dfRuntime = df.loc[df['Design'].str.contains('80')].sort_values(by=['COMPONENTS'], ascending=False)\n",
    "dfRuntime['Design'] = [x[0:x.rfind('_')] for x in dfRuntime['Design']]\n",
    "dfRuntime = dfRuntime.set_index('Design')\n",
    "numIDRShorts = dfRuntime['IDRShort']\n",
    "dfRuntime = dfRuntime[['GR', 'IDR', 'FDR']]\n",
    "ax = dfRuntime.plot.bar(stacked=True)\n",
    "\n",
    "numBars = int(len(ax.patches)/3)\n",
    "for rect, value in zip(ax.patches[numBars:numBars*2], numIDRShorts):\n",
    "  h = rect.get_height() /2.\n",
    "  w = rect.get_width() /2.\n",
    "  x, y = rect.get_xy()\n",
    "  ax.text(x+w, y+h, value, horizontalalignment='center',verticalalignment='center')\n",
    "\n",
    "ax.set_ylabel('Runtime in seconds')\n",
    "ax.set_xlabel('Designs (80% row utilization)')\n",
    "ax.legend([\"Global Routing\", \"Initial Detailed Routing\", \"Complete Detailed Routing\"])\n",
    "plt.title('Routing Runtime Break Down')\n",
    "# plt.savefig('routing_runtime.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg IDR short (considering full routed circuits only)\n",
    "idrShort = []\n",
    "for x in range(70, 91):\n",
    "  tempDf = df.loc[df['Design'].str.contains(str(x))]\n",
    "  tempDf = tempDf.loc[tempDf['FDRTotal'] == 0]\n",
    "  avgIDRShort = sum(tempDf['IDRShort']/len(tempDf))\n",
    "  idrShort.append(avgIDRShort)\n",
    "    \n",
    "plt.plot([y for y in range(70, 91)], idrShort, color = 'r')\n",
    "plt.xlabel(\"Design Density (Row Utilization %)\")\n",
    "plt.ylabel(\"Initial Detailed Routing Short Violations (IDRV)\")\n",
    "plt.title('Average IDR Short x Row Utilization (Only fully routable circuits)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0532a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg IDR short (considering full routed circuits only)\n",
    "fdrRuntime = []\n",
    "for x in range(70, 91):\n",
    "  tempDf = df.loc[df['Design'].str.contains(str(x))]\n",
    "  tempDf = tempDf.loc[tempDf['FDRTotal'] == 0]\n",
    "  fdr = sum(tempDf['FDR']/len(tempDf))\n",
    "  fdrRuntime.append(fdr)\n",
    "\n",
    "plt.plot([y for y in range(70, 91)], fdrRuntime, color = 'r')\n",
    "plt.xlabel(\"Design Density (Row Utilization %)\")\n",
    "plt.ylabel(\"Runtime (seconds)\")\n",
    "plt.title('Average Runtime to complete routing (Only fully routable circuits)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
