{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e3a2b8",
   "metadata": {},
   "source": [
    "# Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f04caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/\n",
    "https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right\n",
    "\n",
    "a figura com drvs justifica muito bem a escolha de 80% para teste\n",
    "\n",
    "\n",
    "fazer eval em todos dfs de 80%, adicionar epoch e indices etc para depois pegar caso necessario\n",
    "pegar melhor modelo olhando o loss e aplicar pra todos circuitos de teste fcn, ou fcn_large\n",
    "\n",
    "\n",
    "\n",
    "Figura:\n",
    "como alguem faria para usar o preditor\n",
    "como alguem faria para testar com outra tecnologia o preditor\n",
    "explicar que ele he independente de tecnologia\n",
    "fluxograma mostrando a parte do ORDF e a parte do INNOVUS para geracao dos benchamrks\n",
    "dps para geracao dos dados de treino e inferencia.\n",
    "Explicar o problema dos dados, não é só uma questão de armazenamento, mas a leitura deles\n",
    "tbm seria muito demorada inviabilizando o treino do modelo.\n",
    "justificar o porque de pegar soh short"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb56f37",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9021c96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c1dc8",
   "metadata": {},
   "source": [
    "# Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training performace\n",
    "trainResultDF = pickle.load(open('results/fcn/trainResultDF.pkl', 'rb'))\n",
    "epochs = {x for x in trainResultDF['epoch']}\n",
    "print('epoch, tp, tn, fp, fn')\n",
    "for x in range(len(epochs)):\n",
    "  epochDF = trainResultDF.loc[trainResultDF['epoch'] == x]\n",
    "  print(x, epochDF['tp'].sum(), epochDF['tn'].sum(), epochDF['fp'].sum(), epochDF['fn'].sum(), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training metrics for a given design\n",
    "# TODO: Maybe change this to take the average for all types of the same design\n",
    "trainResultDF = pickle.load(open('results/fcn/trainResultDF.pkl', 'rb'))\n",
    "design = 'aes_81'\n",
    "sortedDF = trainResultDF.loc[trainResultDF['design'] == design].sort_values(by=['epoch'])\n",
    "ytrain = [x for x in sortedDF['tp']]\n",
    "yval = [x for x in sortedDF['tn']]\n",
    "plt.plot(ytrain, label = \"tp\")\n",
    "plt.plot(yval, label = \"tn\")\n",
    "plt.legend()\n",
    "plt.title(design)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9fc59e",
   "metadata": {},
   "source": [
    "# Cross Validation Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98856eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossValPath = '/home/sheiny/workspace/Predictor/results/'\n",
    "pkls = [crossValPath+x for x in os.listdir(crossValPath) if '.pkl' in x]\n",
    "\n",
    "cvDicts = []\n",
    "for pkl in pkls:\n",
    "  df = pickle.load(open(pkl, 'rb'))\n",
    "  runs = {(row['Design'], row['Density']) for index, row in df.iterrows()}\n",
    "  runLabel = ''\n",
    "  for x in runs:\n",
    "    runLabel += x[0]+str(x[1])+', '\n",
    "  tp = sum(df['tp'])\n",
    "  tn = sum(df['tn'])\n",
    "  fp = sum(df['fp'])\n",
    "  fn = sum(df['fn'])\n",
    "  precision = tp/(tp + fp)\n",
    "  recall = tp/(tp + fn)\n",
    "  TotalPos = tp+fn\n",
    "  TotalNeg = fp+tn\n",
    "  PosRatio = ((tp+fn)/(tp+fn+fp+tn))*100\n",
    "  tpr = tp/(tp+fn)\n",
    "  spc = tn/(tn+fp)\n",
    "  acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "  sqrt = math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "  mcc = 0\n",
    "  if sqrt != 0:\n",
    "    mcc = ((tp * tn) - (fp * fn))/sqrt\n",
    "  cvDicts.append({'Designs':runLabel[:-2],\n",
    "                  'tp':tp, 'tn':tn, 'fp':fp, 'fn':fn,\n",
    "                  'PosRatio%':PosRatio,\n",
    "                  'tpr':tpr, 'spc':spc, 'acc':acc, 'MCC[-1:1]':mcc})\n",
    "cvDf = pd.DataFrame.from_dict(cvDicts)\n",
    "cvDf.set_index('Designs', inplace=True)\n",
    "cvDf.loc['mean'] = cvDf.mean()\n",
    "cvDf.loc['min'] = cvDf.min()\n",
    "cvDf.loc['max'] = cvDf.max()\n",
    "cvDf.to_csv('results/cvResult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d08714",
   "metadata": {},
   "source": [
    "# Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5c3d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl = '/home/sheiny/workspace/Predictor/results/predictRuns.pkl'\n",
    "df = pickle.load(open(pkl, 'rb'))\n",
    "\n",
    "circuitResultDict = []\n",
    "runs = {(row['Design'], row['Density']) for index, row in df.iterrows()}\n",
    "for run in runs:\n",
    "  tempDf = df.loc[(df['Design'] == run[0]) & (df['Density'] == run[1])]\n",
    "  tp = sum(tempDf['tp'])\n",
    "  tn = sum(tempDf['tn'])\n",
    "  fp = sum(tempDf['fp'])\n",
    "  fn = sum(tempDf['fn'])\n",
    "  precision = tp/(tp + fp)\n",
    "  recall = tp/(tp + fn)\n",
    "  TotalPos = tp+fn\n",
    "  TotalNeg = fp+tn\n",
    "  PosRatio = ((tp+fn)/(tp+fn+fp+tn))*100\n",
    "  tpr = tp/(tp+fn)\n",
    "  spc = tn/(tn+fp)\n",
    "  acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "  sqrt = math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "  mcc = 0\n",
    "  if sqrt != 0:\n",
    "    mcc = ((tp * tn) - (fp * fn))/sqrt\n",
    "  circuitResultDict.append({'Design':run[0]+str(run[1]),\n",
    "                            'tp':str(tp)+' ('+str(int(tpr*100))+'%)', 'tn':int(tn),\n",
    "                            'fp':int(fp), 'fn':int(fn),\n",
    "                            'PosRatio%':PosRatio,\n",
    "                            'spc %':spc*100, 'acc %':acc*100, 'MCC[-1:1]':mcc})\n",
    "resultDf = pd.DataFrame.from_dict(circuitResultDict)\n",
    "resultDf.set_index('Design', inplace=True)\n",
    "resultDf.to_csv('results/predictionResult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710e3747",
   "metadata": {},
   "source": [
    "# Plot DRVs and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e12dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = '/data/CSVWhole/aes/'\n",
    "modelPath = 'results/fcn/model_18.pkl'\n",
    "outPath = 'predictions/aes18'\n",
    "\n",
    "\n",
    "\n",
    "def writePredictionFile(outFile, nodesToWrite):\n",
    "  with open(outFile, 'w') as fp:\n",
    "    for node in nodesToWrite:\n",
    "      fp.write(str(node)+'\\n')\n",
    "  fp.close()\n",
    "\n",
    "def predict(model, pkl):\n",
    "  testDf = pd.read_pickle(pkl, compression='zip')\n",
    "  labels = testDf.pop(testDf.columns.values[-1])\n",
    "  nodeIDs = testDf.pop(testDf.columns.values[0])#drop first column which contains the nodeIds\n",
    "  testHyperImages = np.array(testDf).reshape(len(testDf),22,33,33)\n",
    "  predictions = model.predict(testHyperImages)\n",
    "  return nodeIDs, predictions, labels\n",
    "\n",
    "model = pickle.load(open(modelPath, 'rb'))\n",
    "pkls = [design+x for x in os.listdir(design) if '.pkl' in x]\n",
    "pkls.sort(key = lambda x : int(x[x.rfind('_')+1:x.find('.')]))\n",
    "results = []\n",
    "for pkl in pkls:\n",
    "  results.append(predict(model, pkl))\n",
    "\n",
    "tp = []\n",
    "tn = []\n",
    "fp = []\n",
    "fn = []\n",
    "for x, y, z in results:\n",
    "  nodeIDs = [int(n) for n in x]\n",
    "  predictions = y > 0.5\n",
    "  for id, prediction, actual in zip(nodeIDs, predictions, z):\n",
    "    if prediction == actual and actual == True:\n",
    "      tp.append(id)\n",
    "    elif prediction == actual and actual == False:\n",
    "      tn.append(id)\n",
    "    elif prediction != actual and actual == True:\n",
    "      fn.append(id)\n",
    "    else:\n",
    "      fp.append(id)\n",
    "\n",
    "writePredictionFile(outPath+'tp.txt', tp)\n",
    "writePredictionFile(outPath+'tn.txt', tn)\n",
    "writePredictionFile(outPath+'fp.txt', fp)\n",
    "writePredictionFile(outPath+'fn.txt', fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6d418c",
   "metadata": {},
   "source": [
    "# Benchmark Information Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19541ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beware the number of components is wrong!!! It is considering filler cells\n",
    "df = pd.read_pickle('benchmarkInfo/benchmark.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4746e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Info\n",
    "benchmarkDf = df.loc[df['Design'].str.contains('80')]\n",
    "columnsToDrop = ['SPECIALNETS','IDRShort', 'IDRTotal', 'FDRShort', 'FDRTotal', 'GR', 'IDR', 'FDR']\n",
    "benchmarkDf = benchmarkDf.drop(columns=columnsToDrop)\n",
    "benchmarkDf.sort_values(by=['COMPONENTS'], ascending=False)\n",
    "benchmarkDf.to_csv('benchmarkDf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a92600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot Routing Runtime Break Down\n",
    "dfRuntime = df.loc[df['Design'].str.contains('80')].sort_values(by=['COMPONENTS'], ascending=False)\n",
    "dfRuntime['Design'] = [x[0:x.rfind('_')] for x in dfRuntime['Design']]\n",
    "dfRuntime = dfRuntime.set_index('Design')\n",
    "numIDRShorts = dfRuntime['IDRShort']\n",
    "dfRuntime = dfRuntime[['GR', 'IDR', 'FDR']]\n",
    "ax = dfRuntime.plot.bar(stacked=True)\n",
    "\n",
    "numBars = int(len(ax.patches)/3)\n",
    "for rect, value in zip(ax.patches[numBars:numBars*2], numIDRShorts):\n",
    "  h = rect.get_height() /2.\n",
    "  w = rect.get_width() /2.\n",
    "  x, y = rect.get_xy()\n",
    "  ax.text(x+w, y+h, value, horizontalalignment='center',verticalalignment='center')\n",
    "\n",
    "ax.set_ylabel('Runtime in seconds')\n",
    "ax.set_xlabel('Designs (80% row utilization)')\n",
    "ax.legend([\"Global Routing\", \"Initial Detailed Routing\", \"Complete Detailed Routing\"])\n",
    "plt.title('Routing Runtime Break Down')\n",
    "# plt.savefig('routing_runtime.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg IDR short (considering full routed circuits only)\n",
    "idrShort = []\n",
    "for x in range(70, 91):\n",
    "  tempDf = df.loc[df['Design'].str.contains(str(x))]\n",
    "  tempDf = tempDf.loc[tempDf['FDRTotal'] == 0]\n",
    "  avgIDRShort = sum(tempDf['IDRShort']/len(tempDf))\n",
    "  idrShort.append(avgIDRShort)\n",
    "    \n",
    "plt.plot([y for y in range(70, 91)], idrShort, color = 'r')\n",
    "plt.xlabel(\"Design Density (Row Utilization %)\")\n",
    "plt.ylabel(\"Initial Detailed Routing Short Violations (IDRV)\")\n",
    "plt.title('Average IDR Short x Row Utilization (Only fully routable circuits)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0532a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg IDR short (considering full routed circuits only)\n",
    "fdrRuntime = []\n",
    "for x in range(70, 91):\n",
    "  tempDf = df.loc[df['Design'].str.contains(str(x))]\n",
    "  tempDf = tempDf.loc[tempDf['FDRTotal'] == 0]\n",
    "  fdr = sum(tempDf['FDR']/len(tempDf))\n",
    "  fdrRuntime.append(fdr)\n",
    "\n",
    "plt.plot([y for y in range(70, 91)], fdrRuntime, color = 'r')\n",
    "plt.xlabel(\"Design Density (Row Utilization %)\")\n",
    "plt.ylabel(\"Runtime (seconds)\")\n",
    "plt.title('Average Runtime to complete routing (Only fully routable circuits)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
