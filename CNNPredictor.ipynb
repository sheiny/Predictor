{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e3a2b8",
   "metadata": {},
   "source": [
    "# Reads"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26601f4a",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/\n",
    "https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right\n",
    "\n",
    "a figura com drvs justifica muito bem a escolha de 80% para teste\n",
    "\n",
    "\n",
    "fazer eval em todos dfs de 80%, adicionar epoch e indices etc para depois pegar caso necessario\n",
    "pegar melhor modelo olhando o loss e aplicar pra todos circuitos de teste fcn, ou fcn_large\n",
    "\n",
    "ai no final pegar o melhor entre  fcn e fcn_large\n",
    "e fazer k fold cross validation nos 80 como sao 10 circuitos acho q vou fazer k=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f04caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Figura:\n",
    "como alguem faria para usar o preditor\n",
    "como alguem faria para testar com outra tecnologia o preditor\n",
    "explicar que ele he independente de tecnologia\n",
    "fluxograma mostrando a parte do ORDF e a parte do INNOVUS para geracao dos benchamrks\n",
    "dps para geracao dos dados de treino e inferencia.\n",
    "Explicar o problema dos dados, não é só uma questão de armazenamento, mas a leitura deles\n",
    "tbm seria muito demorada inviabilizando o treino do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb56f37",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9021c96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea80aed",
   "metadata": {},
   "source": [
    "# Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ac440",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalMetrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "               tf.keras.metrics.FalsePositives(name='fp'),\n",
    "               tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "               tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall'),\n",
    "               tf.keras.metrics.AUC(name='auc')]\n",
    "\n",
    "# FCN Model\n",
    "def makeFCNModel():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = (22, 33, 33)))\n",
    "  model.add(tf.keras.layers.MaxPooling2D((3, 3)))\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics = evalMetrics)\n",
    "  return model\n",
    "\n",
    "# CNN Model\n",
    "def makeCNNModel():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = (22, 33, 33)))\n",
    "  model.add(tf.keras.layers.MaxPooling2D((3, 3)))\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(128, activation = 'relu'))#Dense\n",
    "  model.add(tf.keras.layers.Dense(128, activation = 'relu'))#Dense\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics = evalMetrics)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9cc971",
   "metadata": {},
   "source": [
    "# Select Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcbc6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('benchmark.pkl', compression='zip')\n",
    "# Get ONLY DRV CLEAN routed circuits\n",
    "df = df.loc[df['FDRTotal'] == 0]\n",
    "# Get all designs to train\n",
    "circuitsToTrain = [x for x in df.loc[df['Design'].str.contains('80') == False].sort_values(by=['Design'])['Design']]\n",
    "\n",
    "allPkls = ['/data/CSV/' + x[0:-3] + '/cts_' + x + '.pkl' for x in circuitsToTrain]\n",
    "allPkls = [x for x in allPkls if os.path.exists(x)]\n",
    "# Get only designs within 75 and 85 except 80\n",
    "allPkls = [x for x in allPkls if int(re.findall(r'\\d+', x)[0]) < 86 and int(re.findall(r'\\d+', x)[0]) > 74]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e54192",
   "metadata": {},
   "source": [
    "# Traning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe552ab2",
   "metadata": {},
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "for pkl in allPkls:\n",
    "  trainDf = pd.read_pickle(pkl, compression='zip')\n",
    "  labels = trainDf.pop(trainDf.columns.values[-1])\n",
    "  totalViol = sum(labels)\n",
    "  pos += totalViol\n",
    "  neg += (len(labels) - totalViol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a3efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 3051\n",
    "neg = 798472\n",
    "total = pos+neg\n",
    "w0 = total/(2*neg)\n",
    "w1 = total/(2*pos)\n",
    "# w1 /= 4\n",
    "weights = {0: w0, 1: w1}\n",
    "sizeBatch = 64  # almost 10% of chance to have viol \\\n",
    "                # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "# weights = {0: 0.5, 1: 100}\n",
    "\n",
    "def train(pklsForTraining, learningModel, modelPath, epochStart, epochEnd, trainResultDF = pd.DataFrame()):\n",
    "  pkls = pklsForTraining.copy()\n",
    "  for epoch in range(epochStart, epochEnd):\n",
    "    random.shuffle(pkls)\n",
    "    for pkl in pkls:\n",
    "      trainDf = pd.read_pickle(pkl, compression='zip')\n",
    "      trainDf = trainDf.reset_index(drop=True)\n",
    "      valDf = trainDf.sample(frac=0.2)\n",
    "      trainDf = trainDf.drop(valDf.index)\n",
    "\n",
    "      labels = trainDf.pop(trainDf.columns.values[-1])\n",
    "      valLabels = valDf.pop(valDf.columns.values[-1])\n",
    "      trainHyperImages = np.array(trainDf).reshape(len(trainDf),22,33,33)\n",
    "      valHyperImages = np.array(valDf).reshape(len(valDf),22,33,33)\n",
    "      print('Epoch: ',epoch,' Training with:', pkl)\n",
    "      train_history = learningModel.fit(x=trainHyperImages,\n",
    "                                       y=labels,\n",
    "                                       verbose=2, #0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "                                       batch_size=sizeBatch,\n",
    "                                       validation_data=(valHyperImages, valLabels),\n",
    "                                       class_weight=weights)\n",
    "      historyDf = pd.DataFrame(train_history.history)\n",
    "      historyDf['epoch'] = epoch\n",
    "      historyDf['design'] = pkl[pkl.rfind('/')+5:pkl.find('.')]\n",
    "      trainResultDF = pd.concat([trainResultDF, historyDf])\n",
    "    pickle.dump(learningModel, open(modelPath+'model_'+str(epoch)+'.pkl', 'wb'))\n",
    "    pickle.dump(trainResultDF, open(modelPath+'trainResultDF.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad78d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = 'cnn/'\n",
    "useFCN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e109432",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = 'fcn/'\n",
    "useFCN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447cd960",
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 5\n",
    "\n",
    "if os.path.exists(modelPath) == False:\n",
    "  os.mkdir(modelPath)\n",
    "\n",
    "models = [x for x in os.listdir(modelPath)]\n",
    "lastRunEpoch = 0\n",
    "learningModel = None\n",
    "trainResultDF = pd.DataFrame()\n",
    "if len(models) > 0:\n",
    "  if 'trainResultDF.pkl' in models:\n",
    "    models.remove('trainResultDF.pkl')\n",
    "  models.sort()\n",
    "  lastModel = models[-1]\n",
    "  lastRunEpoch = int(lastModel[lastModel.find('_')+1:lastModel.find('.')])\n",
    "  learningModel = pickle.load(open(modelPath+'model_'+str(lastRunEpoch)+'.pkl', 'rb'))\n",
    "  lastRunEpoch += 1\n",
    "  trainResultDF = pickle.load(open(modelPath+'trainResultDF.pkl', 'rb'))\n",
    "else:\n",
    "  learningModel = makeFCNModel() if useFCN else makeCNNModel()\n",
    "\n",
    "train(allPkls, learningModel, modelPath, lastRunEpoch, numEpochs, trainResultDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493c48c",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d16b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, pkl):\n",
    "  testDf = pd.read_pickle(pkl, compression='zip')\n",
    "  labels = testDf.pop(testDf.columns.values[-1])\n",
    "  testHyperImages = np.array(testDf).reshape(len(testDf),22,33,33)\n",
    "  result = model.evaluate(testHyperImages, labels)\n",
    "  resultDict = {m:r for (m, r) in zip(model.metrics_names, result)}\n",
    "  return resultDict\n",
    "\n",
    "#circuitsToTest = [x for x in os.listdir('/data/CSVWhole/')]\n",
    "#random.shuffle(circuitsToTest)\n",
    "circuitsToTest = ['tinyRocket', 'jpeg', 'swerv', 'bp_fe', 'bp_be', 'swerv_wrapper', 'dynamic_node', 'bp_multi', 'aes', 'ibex']\n",
    "circuitPaths = ['/data/CSVWhole/'+x+'/' for x in circuitsToTest]\n",
    "\n",
    "crossValItrs = []\n",
    "i = 0\n",
    "for x in range(len(circuitPaths)):\n",
    "  if x % 2 == 0:\n",
    "    crossValItrs.append(('Itr'+str(i), circuitPaths[x], circuitPaths[x+1]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b645092",
   "metadata": {},
   "source": [
    "numEpochs = 5\n",
    "\n",
    "for c in crossValItrs:\n",
    "  modelPath = c[0]+'/'\n",
    "  trainPkls = allPkls.copy()\n",
    "  for circuit in circuitPaths:\n",
    "    if circuit != c[1] and circuit != c[2]:\n",
    "      trainPkls += [circuit+x for x in os.listdir(circuit)]\n",
    "  os.mkdir(modelPath)\n",
    "  learningModel = makeFCNModel()\n",
    "  train(trainPkls, learningModel, modelPath, 0, numEpochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c279c1e",
   "metadata": {},
   "source": [
    "resultDF = pd.DataFrame()\n",
    "for itrCV in crossValItrs:\n",
    "  valPkls = [itrCV[1]+x for x in os.listdir(itrCV[1])]\n",
    "  valPkls += [itrCV[2]+x for x in os.listdir(itrCV[2])]\n",
    "  model = pickle.load(open(itrCV[0]+'/model_4.pkl', 'rb'))\n",
    "  itrDf = pd.DataFrame()\n",
    "  for pkl in valPkls:\n",
    "    resultDict = predict(model, pkl)\n",
    "    resultDf = pd.DataFrame(resultDict, index=[0])\n",
    "    resultDf['Itr'] = itrCV[0]\n",
    "    itrDf = pd.concat([itrDf, resultDf], ignore_index=True)\n",
    "  itrDf = itrDf.sum(axis=0)\n",
    "  itrDf = pd.DataFrame(itrDf).T\n",
    "  resultDF = pd.concat([resultDF, itrDf], ignore_index=True)\n",
    "pickle.dump(resultDF, open('finalDFCV.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pickle.load(open('finalDFCV.pkl', 'rb'))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d928d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for index, row in result.iterrows():\n",
    "  tp = row['tp']\n",
    "  tn = row['tn']\n",
    "  fp = row['fp']\n",
    "  fn = row['fn']\n",
    "  precision = tp/(tp + fp)\n",
    "  recall = tp/(tp + fn)\n",
    "  TotalPos = tp+fn\n",
    "  TotalNeg = fp+tn\n",
    "  PosRatio = ((tp+fn)/(tp+fn+fp+tn))*100\n",
    "  tpr = tp/(tp+fn)\n",
    "  spc = tn/(tn+fp)\n",
    "  fa = fp/(tn+fp)\n",
    "  acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "  sqrt = math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "  mcc = 0\n",
    "  if sqrt != 0:\n",
    "    mcc = ((tp * tn) - (fp * fn))/sqrt\n",
    "  rows.append({'tp':tp, 'tn':tn, 'fp':fp, 'fn':fn,\n",
    "               'PosRatio%':PosRatio,\n",
    "               'tpr':tpr, 'spc':spc, 'acc':acc, 'MCC[-1:1]':mcc})\n",
    "  print()\n",
    "\n",
    "valCircuits = []\n",
    "i = 0\n",
    "for x in range(len(circuitsToTest)):\n",
    "  if x % 2 == 0:\n",
    "    valCircuits.append((circuitsToTest[x]+', '+circuitsToTest[x+1]))\n",
    "    i += 1\n",
    "crossValItrs\n",
    "\n",
    "crossValResultDF = pd.DataFrame(rows, index=valCircuits)\n",
    "crossValResultDF.loc['mean'] = crossValResultDF.mean()\n",
    "crossValResultDF.index.name = 'Circuits'\n",
    "crossValResultDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba6e3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c28a871",
   "metadata": {},
   "source": [
    "# Loss Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa4a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in ['cnn', 'fcn']:\n",
    "for model in ['Itr0', 'Itr1', 'Itr2', 'Itr3', 'Itr4']:\n",
    "  df = pickle.load(open(model+'/trainResultDF.pkl', 'rb'))\n",
    "  for epoch in range(min(df['epoch']), max(df['epoch'])+1):\n",
    "    tp = sum(df.loc[df['epoch'] == epoch]['tp'])\n",
    "    tn = sum(df.loc[df['epoch'] == epoch]['tn'])\n",
    "    fp = sum(df.loc[df['epoch'] == epoch]['fp'])\n",
    "    fn = sum(df.loc[df['epoch'] == epoch]['fn'])\n",
    "    loss = sum(df.loc[df['epoch'] == epoch]['loss'])\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp/(tp + fn)\n",
    "    print('model:', model, 'epoch:', epoch, 'loss:', loss, 'tp:', tp, 'tn:', tn, 'fp:', fp, 'fn:', fn, 'precision:', precision, 'recall:', recall)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b670af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = '/data/CSVWhole/'\n",
    "modelsToEval = ['fcn/model_4.pkl', 'cnn/model_1.pkl']\n",
    "finalDF = pd.DataFrame()\n",
    "for model in modelsToEval:\n",
    "  learningModel = pickle.load(open(model, 'rb'))\n",
    "  for design in os.listdir(dataPath):\n",
    "    pkls = [x for x in os.listdir(dataPath+design)]\n",
    "    pkls.sort(key=lambda x: int(x[x.rfind('_')+1:x.rfind('.')]))\n",
    "    for pkl in pkls:\n",
    "      resultDict = predict(learningModel, dataPath+design+'/'+pkl)\n",
    "      resultDf = pd.DataFrame(resultDict, index=[0])\n",
    "      resultDf['file'] = int(pkl[pkl.rfind('_')+1:pkl.find('.')])\n",
    "      resultDf['design'] = pkl[pkl.find('_')+1:pkl.rfind('_')]\n",
    "      resultDf['model'] = model[:model.find('.')]\n",
    "      finalDF = pd.concat([finalDF, resultDf], ignore_index=True)\n",
    "    pickle.dump(finalDF, open('finalDF.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a5a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('exp9Models/model_4.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72568c30",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d3781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainResultDF = pickle.load(open('EXP9trainResultDF.pkl', 'rb'))\n",
    "trainResultDF.shape\n",
    "# plt.plot(train_history.history['loss'][0:50])\n",
    "# plt.plot(train_history.history['val_loss'][0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b50ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(min(trainResultDF['epoch']), max(trainResultDF['epoch'])+1):\n",
    "  loss = sum(trainResultDF.loc[trainResultDF['epoch'] == epoch]['loss'])\n",
    "  valLoss = sum(trainResultDF.loc[trainResultDF['epoch'] == epoch]['val_loss'])\n",
    "  print('epoch:', epoch, ' loss: ', loss, ' valLoss: ', valLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a697dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = 'jpeg_79'\n",
    "sortedDF = trainResultDF.loc[trainResultDF['design'] == design].sort_values(by=['epoch'])\n",
    "ytrain = [x for x in sortedDF['loss']]\n",
    "yval = [x for x in sortedDF['val_loss']]\n",
    "plt.plot(ytrain, label = \"ytrain\")\n",
    "plt.plot(yval, label = \"yval\")\n",
    "plt.legend()\n",
    "plt.title(design)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e41f2b7",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4407c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, pkl):\n",
    "  testDf = pd.read_pickle(pkl, compression='zip')\n",
    "  labels = testDf.pop(testDf.columns.values[-1])\n",
    "  testHyperImages = np.array(testDf).reshape(len(testDf),22,33,33)\n",
    "  result = model.evaluate(testHyperImages, labels)\n",
    "  resultDict = {m:r for (m, r) in zip(model.metrics_names, result)}\n",
    "  return resultDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb5a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = '/data/CSVWhole/'\n",
    "modelsToEval = ['fcn/model_4.pkl', 'cnn/model_1.pkl']\n",
    "finalDF = pd.DataFrame()\n",
    "for model in modelsToEval:\n",
    "  learningModel = pickle.load(open(model, 'rb'))\n",
    "  for design in os.listdir(dataPath):\n",
    "    pkls = [x for x in os.listdir(dataPath+design)]\n",
    "    pkls.sort(key=lambda x: int(x[x.rfind('_')+1:x.rfind('.')]))\n",
    "    for pkl in pkls:\n",
    "      resultDict = predict(learningModel, dataPath+design+'/'+pkl)\n",
    "      resultDf = pd.DataFrame(resultDict, index=[0])\n",
    "      resultDf['file'] = int(pkl[pkl.rfind('_')+1:pkl.find('.')])\n",
    "      resultDf['design'] = pkl[pkl.find('_')+1:pkl.rfind('_')]\n",
    "      resultDf['model'] = model[:model.find('.')]\n",
    "      finalDF = pd.concat([finalDF, resultDf], ignore_index=True)\n",
    "    pickle.dump(finalDF, open('finalDF.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d670fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "designs = set()\n",
    "for x in finalDF['design']:\n",
    "  designs.add(x)\n",
    "designs\n",
    "for x in designs:\n",
    "  print(x, sum(finalDF.loc[finalDF['design'] == x]['tp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ee0a6",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb50f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_metrics(model, results):\n",
    "  m = {}\n",
    "  for name, value in zip(model.metrics_names, results):\n",
    "    m[name] = value\n",
    "  if m['precision'] + m['recall'] != 0:\n",
    "    f_score = 2 * ((m['precision'] * m['recall'])/(m['precision'] + m['recall']))\n",
    "    m['F-score'] = f_score\n",
    "  else:\n",
    "    m['F-score'] = 0\n",
    "  sqrt = math.sqrt((m['tp']+m['fp'])*(m['tp']+m['fn'])*(m['tn']+m['fp'])*(m['tn']+m['fn']))\n",
    "  if sqrt != 0:\n",
    "    mcc = ((m['tp'] * m['tn']) - (m['fp'] * m['fn']))/sqrt\n",
    "    m['MCC'] = mcc\n",
    "  else:\n",
    "    m['MCC'] = -1\n",
    "  return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d9a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = 'cnn/inference.pkl'\n",
    "sizeBatch = 64 # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "for circuit in os.listdir('/data/CSVWhole/'):\n",
    "  i = 0\n",
    "  resultDF = pd.DataFrame()\n",
    "  for pkl in ['/data/CSVWhole/'+circuit+'/'+x for x in os.listdir('/data/CSVWhole/'+circuit)]:\n",
    "    print(circuit, i, pkl)\n",
    "    testDF = pd.read_pickle(pkl, compression='zip')\n",
    "    testDF = testDF.sample(frac=1).reset_index(drop=True) #Shuffle all rows\n",
    "    testLabels = testDF.pop(testDF.columns.values[-1])\n",
    "    testHyperImages = np.array(testDF).reshape(len(testDF),22,33,33)\n",
    "    baseline_results = model.evaluate(x=testHyperImages,\n",
    "                                      y=testLabels,\n",
    "                                      batch_size=sizeBatch)\n",
    "    test_metrics = calculate_test_metrics(model, baseline_results)\n",
    "    testDF = pd.DataFrame(test_metrics, index=[i])\n",
    "    testDF['design'] = circuit\n",
    "    resultDF = pd.concat([resultDF, testDF], ignore_index=True)\n",
    "    i += 1\n",
    "pickle.dump(resultDF, open(outputPath, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6d418c",
   "metadata": {},
   "source": [
    "# Benchmark Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19541ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('benchmark.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a92600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot Routing Runtime Break Down\n",
    "dfRuntime = df.loc[df['Design'].str.contains('80')].sort_values(by=['COMPONENTS'], ascending=False)\n",
    "dfRuntime['Design'] = [x[0:x.rfind('_')] for x in dfRuntime['Design']]\n",
    "dfRuntime = dfRuntime.set_index('Design')\n",
    "dfRuntime = dfRuntime[['GR', 'IDR', 'FDR']]\n",
    "ax = dfRuntime.plot.bar(stacked=True)\n",
    "ax.set_ylabel('Runtime in seconds')\n",
    "ax.set_xlabel('Designs (80% row utilization)')\n",
    "ax.legend([\"Global Routing\", \"Initial Detailed Routing\", \"Complete Detailed Routing\"])\n",
    "plt.title('Routing Runtime Break Down For 80% Row Utilization Designs')\n",
    "# plt.savefig('routing_runtime.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02700b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO adicionar nas barras laranjas os numeros de IDRVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e46745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot Routing Runtime Break Down\n",
    "dfRuntime = df.loc[df['Design'].str.contains('80')].sort_values(by=['COMPONENTS'], ascending=False)\n",
    "dfRuntime['Design'] = [x[0:x.rfind('_')] for x in dfRuntime['Design']]\n",
    "dfRuntime = dfRuntime.set_index('Design')\n",
    "dfRuntime = dfRuntime[['IDRShort']]\n",
    "ax = dfRuntime.plot.bar(stacked=True)\n",
    "ax.set_ylabel('Initial Detailed Routing Violations (IDRVs)')\n",
    "ax.set_xlabel('Designs (80% row utilization)')\n",
    "plt.title('Number of IDRVs For 80% Row Utilization Designs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg IDR short (considering full routed circuits only)\n",
    "idrShort = []\n",
    "for x in range(70, 91):\n",
    "  tempDf = df.loc[df['Design'].str.contains(str(x))]\n",
    "  tempDf = tempDf.loc[tempDf['FDRTotal'] == 0]\n",
    "  avgIDRShort = sum(tempDf['IDRShort']/len(tempDf))\n",
    "  idrShort.append(avgIDRShort)\n",
    "    \n",
    "plt.plot([y for y in range(70, 91)], idrShort, color = 'r')\n",
    "plt.xlabel(\"Design Density (Row Utilization %)\")\n",
    "plt.ylabel(\"Initial Detailed Routing Short Violations (IDRV)\")\n",
    "plt.title('Average IDR Short x Row Utilization (Only DRV Free Designs)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e531c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar o valor maximo do eixo y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0532a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg IDR short (considering full routed circuits only)\n",
    "fdrRuntime = []\n",
    "for x in range(70, 91):\n",
    "  tempDf = df.loc[df['Design'].str.contains(str(x))]\n",
    "  tempDf = tempDf.loc[tempDf['FDRTotal'] == 0]\n",
    "  fdr = sum(tempDf['FDR']/len(tempDf))\n",
    "  fdrRuntime.append(fdr)\n",
    "\n",
    "plt.plot([y for y in range(70, 91)], fdrRuntime, color = 'r')\n",
    "plt.xlabel(\"Design Density (Row Utilization %)\")\n",
    "plt.ylabel(\"Runtime (seconds)\")\n",
    "plt.title('Average Runtime to complete routing (Only DRV Free Designs)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735fc326",
   "metadata": {},
   "source": [
    "# Benchmark Info"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37abbe93",
   "metadata": {},
   "source": [
    "def numDRVs(file):\n",
    "  shortViol = 0\n",
    "  totalViol = 0\n",
    "  for line in open(file, 'r').readlines():\n",
    "    if 'Metal Short' in line:\n",
    "      shortViol += 1\n",
    "    if 'Total Violations' in line:\n",
    "      totalViol = int(line.split(' ')[5])\n",
    "  return [shortViol, totalViol]\n",
    "\n",
    "def getDefInfo(file):\n",
    "  info = {x:0 for x in ['COMPONENTS', 'NETS', 'SPECIALNETS', 'PINS', 'BLOCKAGES']}\n",
    "  for line in open(file, 'r').readlines():\n",
    "    tokens = line.split(' ')\n",
    "    if tokens[0] in info:\n",
    "      info[tokens[0]] = int(tokens[1])\n",
    "  return info\n",
    "\n",
    "def getRuntime(file):\n",
    "  runtime = {x:-1 for x in ['GR', 'IDR', 'FDR']}\n",
    "  val = []\n",
    "  for line in open(file,\"r\"):\n",
    "      val.append(int(line.split(' ')[0]))\n",
    "  runtime['GR'] = val[0]\n",
    "  runtime['IDR'] = val[1]\n",
    "  runtime['FDR'] = val[2]\n",
    "  return runtime\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "benchmarkPath = '/home/sheiny/workspace/Benchmarks/RoutedOpenCores/'\n",
    "allCircuits = [benchmarkPath+circuit+'/base/' for circuit in os.listdir(benchmarkPath) if os.path.exists(benchmarkPath+circuit+'/base/')]\n",
    "\n",
    "allCircuits.remove(benchmarkPath+'bp/base/')#Pad problem (too much congested at bottom left)\n",
    "allCircuits.remove(benchmarkPath+'gcd/base/')#Too small\n",
    "\n",
    "for circuit in allCircuits:\n",
    "  for csv in os.listdir(circuit):\n",
    "    if 'Runtime' not in csv:\n",
    "      continue\n",
    "    design = csv[csv.find('_')+1:csv.find('Runtime')]\n",
    "\n",
    "    IDRShort, IDRTotal = numDRVs(circuit+'cts_'+design+'FirstDR.rpt')\n",
    "    FDRShort, FDRTotal = numDRVs(circuit+'cts_'+design+'FinalDR.rpt')\n",
    "\n",
    "    info = getDefInfo(circuit+'cts_'+design+'.def')\n",
    "    drvs = {'IDRShort':IDRShort, 'IDRTotal':IDRTotal, 'FDRShort':FDRShort, 'FDRTotal':FDRTotal}\n",
    "    runtime = getRuntime(circuit+'cts_'+design+'Runtime.out')\n",
    "    dfVals = {'Design':design}\n",
    "    dfVals.update(info)\n",
    "    dfVals.update(drvs)\n",
    "    dfVals.update(runtime)\n",
    "    dfTemp = pd.DataFrame(dfVals, index=[0])\n",
    "    df = pd.concat([df, dfTemp], ignore_index=True)\n",
    "df.to_pickle('benchmark.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d619a4",
   "metadata": {},
   "source": [
    "# Compress All CSVs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c3bb6cc",
   "metadata": {},
   "source": [
    "# MULTIPLE CSVs per circuit (Train)\n",
    "allCircuits = ['/data/CSV/'+x+'/' for x in os.listdir('/data/CSV/')]\n",
    "allCircuits.sort()\n",
    "for circuit in allCircuits:\n",
    "  files = os.listdir(circuit)\n",
    "  files.sort()\n",
    "  for csv in files:\n",
    "    if csv == 'cts_swerv_90_viol.csv' or csv == 'cts_swerv_89_viol.csv': #too many viol\n",
    "      continue\n",
    "    if 'viol' not in csv:\n",
    "      continue\n",
    "    if csv[0:csv.find('_viol')]+'.pkl' in files: #Already compressed\n",
    "      continue\n",
    "    print('Compressing ', csv[0:csv.find('_viol')])\n",
    "    dfViol = pd.read_csv(circuit+csv, dtype=np.float32, header=None)\n",
    "    dfSurround = pd.read_csv(circuit+csv[0:csv.find('viol')]+'surround.csv', dtype=np.float32, header=None)\n",
    "    dfNonViol = pd.read_csv(circuit+csv[0:csv.find('viol')]+'nonViol.csv', dtype=np.float32, header=None)\n",
    "    df = pd.concat([dfViol, dfSurround, dfNonViol], ignore_index=True)\n",
    "    df.to_pickle(circuit+csv[0:csv.find('_viol')]+'.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bad5ab2a",
   "metadata": {},
   "source": [
    "# A SINGLE CSV per circuit (TEST)\n",
    "allCircuits = ['/data/CSV/'+x+'/' for x in os.listdir('/data/CSV/')]\n",
    "allCircuits.sort()\n",
    "for circuit in allCircuits:\n",
    "  files = os.listdir(circuit)\n",
    "  files.sort()\n",
    "  for csv in files:\n",
    "    if '.csv' not in csv:\n",
    "      continue\n",
    "    if csv[0:csv.find('.')]+'_0.pkl' in files: #Already compressed\n",
    "      print('skipping ',csv)\n",
    "      continue\n",
    "\n",
    "    i = 0\n",
    "    print('Compressing ', csv[0:csv.find('.')])\n",
    "    for df in pd.read_csv(circuit+csv, dtype=np.float32, header=None, chunksize=10000):\n",
    "      df.to_pickle(circuit+csv[0:csv.find('.')]+'_'+str(i)+'.pkl', compression='zip')\n",
    "      i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80605bb1",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4afe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = sklearn.preprocessing.StandardScaler()\n",
    "# trainHyperImages = scaler.fit_transform(trainHyperImages)\n",
    "# valHyperImages = scaler.transform(valHyperImages)\n",
    "\n",
    "# scaler = sklearn.preprocessing.StandardScaler()\n",
    "# labels = df[33*33*22]\n",
    "# df[0:33*33*22-1] = scaler.fit_transform(df[0:33*33*22-1]).round(decimals=2)\n",
    "# df[33*33*22] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9156d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(frac=1).reset_index(drop=True) #Shuffle all rows\n",
    "# dfVal = df.sample(frac=0.2)\n",
    "# df = df.drop(dfVal.index)\n",
    "\n",
    "# labels = df.pop(df.columns.values[-1])\n",
    "# valLabels = dfVal.pop(dfVal.columns.values[-1])\n",
    "# trainHyperImages = np.array(df).reshape(len(df),22,33,33)\n",
    "# valHyperImages = np.array(dfVal).reshape(len(dfVal),22,33,33)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
