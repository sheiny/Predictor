{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb56f37",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9021c96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d4875",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a02b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aesOriginal = pd.read_pickle('/data/CSVWhole/aes/cts_aes_80_0.pkl', compression='zip')\n",
    "df = pd.read_csv('/home/sheiny/workspace/Benchmarks/RoutedOpenCores/aes.csv', dtype=np.float32, header=None)\n",
    "\n",
    "nodeIDs = df.pop(df.columns.values[0])\n",
    "\n",
    "newNames = {x:np.int64(x)-1 for x in df.columns}\n",
    "df.rename(columns = newNames, inplace = True)\n",
    "df.equals(aesOriginal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea80aed",
   "metadata": {},
   "source": [
    "# Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ac440",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalMetrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "               tf.keras.metrics.FalsePositives(name='fp'),\n",
    "               tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "               tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall'),\n",
    "               tf.keras.metrics.AUC(name='auc')]\n",
    "\n",
    "# FCN Model\n",
    "def makeFCNModel():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = (22, 33, 33)))\n",
    "  model.add(tf.keras.layers.MaxPooling2D((3, 3)))\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics = evalMetrics)\n",
    "  return model\n",
    "\n",
    "# CNN Model\n",
    "def makeCNNModel():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = (22, 33, 33)))\n",
    "  model.add(tf.keras.layers.MaxPooling2D((3, 3)))\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(128, activation = 'relu'))#Dense\n",
    "  model.add(tf.keras.layers.Dense(128, activation = 'relu'))#Dense\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics = evalMetrics)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9cc971",
   "metadata": {},
   "source": [
    "# Select Training Data (requires benchmark.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1750099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('benchmarkInfo/benchmark.pkl', compression='zip')\n",
    "# Get ONLY DRV CLEAN routed circuits, that have DRVs in their first DR itr.\n",
    "df = df.loc[df['FDRTotal'] == 0]\n",
    "# Get all designs to train\n",
    "circuitsToTrain = [x for x in df.loc[df['Design'].str.contains('80') == False].sort_values(by=['Design'])['Design']]\n",
    "\n",
    "\n",
    "allPkls = ['/data/CSV/' + x[0:-3] + '/cts_' + x + '.pkl' for x in circuitsToTrain]\n",
    "allPkls = [x for x in allPkls if os.path.exists(x)]\n",
    "# Get only designs within 75 and 85 except 80\n",
    "allPkls = [x for x in allPkls if int(re.findall(r'\\d+', x)[0]) < 86 and int(re.findall(r'\\d+', x)[0]) > 74]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e54192",
   "metadata": {},
   "source": [
    "# Traning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe552ab2",
   "metadata": {},
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "for pkl in allPkls:\n",
    "  trainDf = pd.read_pickle(pkl, compression='zip')\n",
    "  labels = trainDf.pop(trainDf.columns.values[-1])\n",
    "  totalViol = sum(labels)\n",
    "  pos += totalViol\n",
    "  neg += (len(labels) - totalViol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a3efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 3051\n",
    "neg = 798472\n",
    "total = pos+neg\n",
    "w0 = total/(2*neg)\n",
    "w1 = total/(2*pos)\n",
    "# w1 /= 4\n",
    "weights = {0: w0, 1: w1}\n",
    "sizeBatch = 64  # almost 10% of chance to have viol \\\n",
    "                # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "# weights = {0: 0.5, 1: 100}\n",
    "\n",
    "def train(pklsForTraining, learningModel, modelPath, epochStart, epochEnd, trainResultDF = pd.DataFrame()):\n",
    "  pkls = pklsForTraining.copy()\n",
    "  for epoch in range(epochStart, epochEnd):\n",
    "    random.shuffle(pkls)\n",
    "    for pkl in pkls:\n",
    "      trainDf = pd.read_pickle(pkl, compression='zip')\n",
    "      trainDf = trainDf.reset_index(drop=True)\n",
    "      valDf = trainDf.sample(frac=0.2)\n",
    "      trainDf = trainDf.drop(valDf.index)\n",
    "\n",
    "      labels = trainDf.pop(trainDf.columns.values[-1])\n",
    "      valLabels = valDf.pop(valDf.columns.values[-1])\n",
    "      #trainDf.pop(trainDf.columns.values[0])#drop first column which contains the nodeIds\n",
    "      #valDf.pop(valDf.columns.values[0])#drop first column which contains the nodeIds\n",
    "      trainHyperImages = np.array(trainDf).reshape(len(trainDf),22,33,33)\n",
    "      valHyperImages = np.array(valDf).reshape(len(valDf),22,33,33)\n",
    "      print('Epoch: ',epoch,' Training with:', pkl)\n",
    "      train_history = learningModel.fit(x=trainHyperImages,\n",
    "                                       y=labels,\n",
    "                                       verbose=2, #0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "                                       batch_size=sizeBatch,\n",
    "                                       validation_data=(valHyperImages, valLabels),\n",
    "                                       class_weight=weights)\n",
    "      historyDf = pd.DataFrame(train_history.history)\n",
    "      historyDf['epoch'] = epoch\n",
    "      historyDf['design'] = pkl[pkl.rfind('/')+5:pkl.find('.')]\n",
    "      trainResultDF = pd.concat([trainResultDF, historyDf])\n",
    "    pickle.dump(learningModel, open(modelPath+'model_'+str(epoch)+'.pkl', 'wb'))\n",
    "    pickle.dump(trainResultDF, open(modelPath+'trainResultDF.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad78d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = 'results/cnn/'\n",
    "useFCN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e109432",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = 'results/fcn/'\n",
    "useFCN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4764a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 100\n",
    "\n",
    "if os.path.exists(modelPath) == False:\n",
    "  os.mkdir(modelPath)\n",
    "\n",
    "models = [x for x in os.listdir(modelPath)]\n",
    "lastRunEpoch = 0\n",
    "learningModel = None\n",
    "trainResultDF = pd.DataFrame()\n",
    "if len(models) > 0:\n",
    "  if 'trainResultDF.pkl' in models:\n",
    "    models.remove('trainResultDF.pkl')\n",
    "  models.sort(key = lambda x : int(x[x.find('_')+1:x.find('.')]))\n",
    "  lastModel = models[-1]\n",
    "  lastRunEpoch = int(lastModel[lastModel.find('_')+1:lastModel.find('.')])\n",
    "  learningModel = pickle.load(open(modelPath+'model_'+str(lastRunEpoch)+'.pkl', 'rb'))\n",
    "  lastRunEpoch += 1\n",
    "  trainResultDF = pickle.load(open(modelPath+'trainResultDF.pkl', 'rb'))\n",
    "else:\n",
    "  learningModel = makeFCNModel() if useFCN else makeCNNModel()\n",
    "\n",
    "train(allPkls, learningModel, modelPath, lastRunEpoch, numEpochs, trainResultDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493c48c",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6478b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('results/fcn/model_12.pkl', 'rb'))\n",
    "outputFile = 'results/cv/fcnCV12.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edc2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, pkl):\n",
    "  testDf = pd.read_pickle(pkl, compression='zip')\n",
    "  labels = testDf.pop(testDf.columns.values[-1])\n",
    "  #testDf.pop(testDf.columns.values[0])\n",
    "  testHyperImages = np.array(testDf).reshape(len(testDf),22,33,33)\n",
    "  result = model.evaluate(testHyperImages, labels)\n",
    "  resultDict = {m:r for (m, r) in zip(model.metrics_names, result)}\n",
    "  return resultDict\n",
    "\n",
    "circuitsToTest = ['/data/CSVWhole/'+x+'/' for x in os.listdir('/data/CSVWhole/')]\n",
    "\n",
    "resultDF = pd.DataFrame()\n",
    "for circuit in circuitsToTest:\n",
    "  pkls = os.listdir(circuit)\n",
    "  itrDf = pd.DataFrame()\n",
    "  for pkl in pkls:\n",
    "    resultDict = predict(model, circuit+pkl)\n",
    "    resultDf = pd.DataFrame(resultDict, index=[0])\n",
    "    itrDf = pd.concat([itrDf, resultDf], ignore_index=True)\n",
    "  itrDf = itrDf.sum(axis=0)\n",
    "  itrDf['Design'] = pkls[0][pkls[0].find('_')+1:pkls[0].rfind('_')]\n",
    "  itrDf = pd.DataFrame(itrDf).T\n",
    "  resultDF = pd.concat([resultDF, itrDf], ignore_index=True)\n",
    "pickle.dump(resultDF, open(outputFile, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b88282",
   "metadata": {},
   "source": [
    "# Benchmark Info (benchmark.pkl)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a40ca311",
   "metadata": {},
   "source": [
    "def numDRVs(file):\n",
    "  shortViol = 0\n",
    "  totalViol = 0\n",
    "  for line in open(file, 'r').readlines():\n",
    "    if 'Metal Short' in line:\n",
    "      shortViol += 1\n",
    "    if 'Total Violations' in line:\n",
    "      totalViol = int(line.split(' ')[5])\n",
    "  return [shortViol, totalViol]\n",
    "\n",
    "def getDefInfo(file):\n",
    "  info = {x:0 for x in ['COMPONENTS', 'NETS', 'SPECIALNETS', 'PINS', 'BLOCKAGES']}\n",
    "  for line in open(file, 'r').readlines():\n",
    "    tokens = line.split(' ')\n",
    "    if tokens[0] in info:\n",
    "      info[tokens[0]] = int(tokens[1])\n",
    "  return info\n",
    "\n",
    "def getRuntime(file):\n",
    "  runtime = {x:-1 for x in ['GR', 'IDR', 'FDR']}\n",
    "  val = []\n",
    "  for line in open(file,\"r\"):\n",
    "      val.append(int(line.split(' ')[0]))\n",
    "  runtime['GR'] = val[0]\n",
    "  runtime['IDR'] = val[1]\n",
    "  runtime['FDR'] = val[2]\n",
    "  return runtime\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "benchmarkPath = '/home/sheiny/workspace/Benchmarks/RoutedOpenCores/'\n",
    "allCircuits = [benchmarkPath+circuit+'/base/' for circuit in os.listdir(benchmarkPath) if os.path.exists(benchmarkPath+circuit+'/base/')]\n",
    "\n",
    "allCircuits.remove(benchmarkPath+'bp/base/')#Pad problem (too much congested at bottom left)\n",
    "allCircuits.remove(benchmarkPath+'gcd/base/')#Too small\n",
    "\n",
    "for circuit in allCircuits:\n",
    "  for csv in os.listdir(circuit):\n",
    "    if 'Runtime' not in csv:\n",
    "      continue\n",
    "    design = csv[csv.find('_')+1:csv.find('Runtime')]\n",
    "\n",
    "    IDRShort, IDRTotal = numDRVs(circuit+'cts_'+design+'FirstDR.rpt')\n",
    "    FDRShort, FDRTotal = numDRVs(circuit+'cts_'+design+'FinalDR.rpt')\n",
    "\n",
    "    info = getDefInfo(circuit+'cts_'+design+'.def')\n",
    "    drvs = {'IDRShort':IDRShort, 'IDRTotal':IDRTotal, 'FDRShort':FDRShort, 'FDRTotal':FDRTotal}\n",
    "    runtime = getRuntime(circuit+'cts_'+design+'Runtime.out')\n",
    "    dfVals = {'Design':design}\n",
    "    dfVals.update(info)\n",
    "    dfVals.update(drvs)\n",
    "    dfVals.update(runtime)\n",
    "    dfTemp = pd.DataFrame(dfVals, index=[0])\n",
    "    df = pd.concat([df, dfTemp], ignore_index=True)\n",
    "df.to_pickle('benchmarkInfo/benchmark.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d619a4",
   "metadata": {},
   "source": [
    "# Compress All CSVs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c3bb6cc",
   "metadata": {},
   "source": [
    "# MULTIPLE CSVs per circuit (Train)\n",
    "allCircuits = ['/data/CSV/'+x+'/' for x in os.listdir('/data/CSV/')]\n",
    "allCircuits.sort()\n",
    "for circuit in allCircuits:\n",
    "  files = os.listdir(circuit)\n",
    "  files.sort()\n",
    "  for csv in files:\n",
    "    if csv == 'cts_swerv_90_viol.csv' or csv == 'cts_swerv_89_viol.csv': #too many viol\n",
    "      continue\n",
    "    if 'viol' not in csv:\n",
    "      continue\n",
    "    if csv[0:csv.find('_viol')]+'.pkl' in files: #Already compressed\n",
    "      continue\n",
    "    print('Compressing ', csv[0:csv.find('_viol')])\n",
    "    dfViol = pd.read_csv(circuit+csv, dtype=np.float32, header=None)\n",
    "    dfSurround = pd.read_csv(circuit+csv[0:csv.find('viol')]+'surround.csv', dtype=np.float32, header=None)\n",
    "    dfNonViol = pd.read_csv(circuit+csv[0:csv.find('viol')]+'nonViol.csv', dtype=np.float32, header=None)\n",
    "    df = pd.concat([dfViol, dfSurround, dfNonViol], ignore_index=True)\n",
    "    df.to_pickle(circuit+csv[0:csv.find('_viol')]+'.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bad5ab2a",
   "metadata": {},
   "source": [
    "# A SINGLE CSV per circuit (TEST)\n",
    "allCircuits = ['/data/CSV/'+x+'/' for x in os.listdir('/data/CSV/')]\n",
    "allCircuits.sort()\n",
    "for circuit in allCircuits:\n",
    "  files = os.listdir(circuit)\n",
    "  files.sort()\n",
    "  for csv in files:\n",
    "    if '.csv' not in csv:\n",
    "      continue\n",
    "    if csv[0:csv.find('.')]+'_0.pkl' in files: #Already compressed\n",
    "      print('skipping ',csv)\n",
    "      continue\n",
    "\n",
    "    i = 0\n",
    "    print('Compressing ', csv[0:csv.find('.')])\n",
    "    for df in pd.read_csv(circuit+csv, dtype=np.float32, header=None, chunksize=10000):\n",
    "      df.to_pickle(circuit+csv[0:csv.find('.')]+'_'+str(i)+'.pkl', compression='zip')\n",
    "      i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
