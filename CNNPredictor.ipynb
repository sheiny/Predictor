{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from keras.callbacks import CSVLogger\n",
    "import os\n",
    "from enum import Enum\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "model_name = \"CNN\" #it will create a directory with this name to save the model's weights and training history\n",
    "\n",
    "size_batch = 2048 # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "epochs_to_train = 300 #300\n",
    "# initial_learning_rate = 4.5e-03 #Eh?Predictor=0.05, default=0.001\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate,\n",
    "#     decay_steps=100000,\n",
    "#     decay_rate=0.94)\n",
    "\n",
    "use_softmax = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (23, 23, 6)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation = 'relu'))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "\n",
    "model.add(layers.AveragePooling2D((3, 3)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(128, activation = 'relu'))\n",
    "model.add(layers.Dense(128, activation = 'relu'))\n",
    "\n",
    "model.add(layers.Dense(2, activation = 'relu'))\n",
    "\n",
    "loss_function = None\n",
    "metrics_evaluate = None\n",
    "if use_softmax:\n",
    "    model.add(layers.Dense(2, activation = 'softmax'))\n",
    "    loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics_evaluate = tf.keras.metrics.CategoricalCrossentropy()\n",
    "else:\n",
    "    model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "    loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics_evaluate = [tf.keras.metrics.TruePositives(name = 'tp'),\n",
    "                        tf.keras.metrics.FalsePositives(name = 'fp'),\n",
    "                        tf.keras.metrics.TrueNegatives(name = 'tn'),\n",
    "                        tf.keras.metrics.FalseNegatives(name = 'fn'),\n",
    "                        tf.keras.metrics.BinaryAccuracy(name = 'accuracy'),\n",
    "                        tf.keras.metrics.Precision(name = 'precision'),\n",
    "                        tf.keras.metrics.Recall(name = 'recall'),\n",
    "                        tf.keras.metrics.AUC(name = 'auc')]\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = loss_function,\n",
    "              metrics = metrics_evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CNN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits = [\"ispd19_test\"+str(x) for x in range(1, 11)]\n",
    "test_circuit = \"ispd19_test10\"\n",
    "if test_circuit in circuits:\n",
    "    circuits.remove(test_circuit)\n",
    "circuits.remove(\"ispd19_test4\")#low density benchmark\n",
    "circuits.remove(\"ispd19_test5\")#low density benchmark\n",
    "circuits.remove(\"ispd19_test9\")#Simillar from test10\n",
    "\n",
    "circuits.extend(['aes', 'blackParrot', 'dynamicNode', 'gcd', 'ibex', 'jpeg', 'swerv', 'TinyRocket'])\n",
    "\n",
    "data_path = './NPYCNN/'\n",
    "\n",
    "file_types = ['violatingNodes', 'surroundingViolNodes', 'nonViolatingNodes']\n",
    "\n",
    "training_data = np.empty((0,23,23,6), dtype=np.int32)\n",
    "image = None\n",
    "if use_softmax:\n",
    "    image = np.empty((0,2), dtype=np.int32)\n",
    "else:\n",
    "    image = np.empty((0), dtype=np.int32)\n",
    "for circuit in circuits:\n",
    "    for file_type in file_types:\n",
    "        file_name = circuit+'_'+file_type+'.npy'\n",
    "        print('Loading: ',circuit,' file_name: ',file_name)\n",
    "        data = np.load(data_path+file_name)\n",
    "        training_data = np.concatenate((training_data, data), axis=0)\n",
    "        \n",
    "        img = None\n",
    "        if use_softmax:\n",
    "            img = np.full((data.shape[0], 2), 0, dtype=np.int32)\n",
    "            if file_type == 'violatingNodes':\n",
    "                img[:, 1] = 1\n",
    "            else:\n",
    "                img[:, 0] = 1\n",
    "        else:\n",
    "            if file_type == 'violatingNodes':\n",
    "                img = np.full((data.shape[0]), 1, dtype=np.int32)\n",
    "            else:\n",
    "                img = np.full((data.shape[0]), 0, dtype=np.int32)\n",
    "        image = np.concatenate((image, img), axis=0)\n",
    "\n",
    "print('training_data: ', training_data.shape)\n",
    "print('image: ', image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = model_name+\"/cp.ckpt\"\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = model_name+\"/cp.ckpt\"\n",
    "\n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "else:\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights at the end of each epoch\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True)\n",
    "# Create a callback that saves model history at the end of each epoch\n",
    "csv_logger = CSVLogger(model_name+\"/model_history_log.csv\", append=True)\n",
    "\n",
    "train_history = model.fit(training_data,\n",
    "                         image,\n",
    "                         batch_size=size_batch,\n",
    "                         epochs=epochs_to_train,\n",
    "                         callbacks=[cp_callback, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "#matplotlib.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = matplotlib.pyplot.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "def computeFScoreAndMCC(df):\n",
    "    df['F-score'] = (2 * df['precision'] * df['recall'])/(df['precision'] + df['recall'])\n",
    "    sqrt = np.sqrt((df['tp']+df['fp'])*(df['tp']+df['fn'])*(df['tn']+df['fp'])*(df['tn']+df['fn']))\n",
    "    df['MCC'] = (df['tp'] * df['tn'] - df['fp'] * df['fn'])/sqrt\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "def plot_df(history_df, metric, size=None):\n",
    "    if size == None:\n",
    "        size = history_df.shape[0]\n",
    "    matplotlib.pyplot.style.use(\"ggplot\")\n",
    "    matplotlib.pyplot.figure()\n",
    "    matplotlib.pyplot.plot(np.arange(0, size), history_df[metric][0:size], label=metric)\n",
    "    matplotlib.pyplot.title(\"Training performace: \"+metric)\n",
    "    matplotlib.pyplot.xlabel(\"Epoch #\")\n",
    "    matplotlib.pyplot.ylabel(metric)\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "def plot_cm(labels, predictions, title=None, output_path=None, p=0.5):\n",
    "    cm = sklearn.metrics.confusion_matrix(labels, predictions > p)\n",
    "    matplotlib.pyplot.figure(figsize=(5,5))\n",
    "    seaborn.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    if title == None:\n",
    "        matplotlib.pyplot.title('Confusion matrix')\n",
    "    else:\n",
    "        matplotlib.pyplot.title(title)\n",
    "    matplotlib.pyplot.ylabel('Actual label')\n",
    "    matplotlib.pyplot.xlabel('Predicted label')\n",
    "    if output_path != None:\n",
    "        matplotlib.pyplot.savefig(output_path)\n",
    "    else:\n",
    "        matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_softmax:\n",
    "    result = model.predict(training_data)\n",
    "    result2 = np.argmax(result, axis=1)\n",
    "    plot_cm(image[:,1], result2, \"Test Confusion Matrix\")\n",
    "else:\n",
    "    result = model.predict(training_data)\n",
    "    plot_cm(image, result, \"Test Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.read_csv(model_name+\"/model_history_log.csv\") #Path to \"model_history_log.csv\"\n",
    "computeFScoreAndMCC(history_df)\n",
    "metrics_to_draw = ['loss', 'F-score', 'MCC', 'precision', 'recall']\n",
    "max_epochs = 30 #Use None to draw the entire history\n",
    "for metric in metrics_to_draw:\n",
    "    plot_df(history_df, metric) #plot_df(history_df, metric, max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_metrics(model, results):\n",
    "    m = {}\n",
    "    for name, value in zip(model.metrics_names, results):\n",
    "        m[name] = value\n",
    "    if m['precision'] + m['recall'] != 0:\n",
    "        f_score = (2 * m['precision'] * m['recall'])/(m['precision'] + m['recall'])\n",
    "        m['F-score'] = f_score\n",
    "    sqrt = math.sqrt((m['tp']+m['fp'])*(m['tp']+m['fn'])*(m['tn']+m['fp'])*(m['tn']+m['fn']))\n",
    "    if sqrt != 0:\n",
    "        mcc = (m['tp'] * m['tn'] - m['fp'] * m['fn'])/sqrt\n",
    "        m['MCC'] = mcc\n",
    "    return m\n",
    "\n",
    "baseline_results = model.evaluate(test_array, test_labels, batch_size=batch_size, verbose=0)\n",
    "metrics = calculate_test_metrics(model, baseline_results)\n",
    "print(metrics)\n",
    "test_predictions_baseline = model.predict(test_array, batch_size=batch_size)\n",
    "plot_cm(test_labels, test_predictions_baseline, \"Test Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Save Data in NPY format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "circuits = [\"ispd19_test\"+str(x) for x in range(1, 11)]\n",
    "circuits.remove(\"ispd19_test4\")#low density benchmark (Older STD Lib)\n",
    "circuits.remove(\"ispd19_test5\")#low density benchmark (Older STD Lib)\n",
    "circuits.remove(\"ispd19_test9\")#Simillar from test10\n",
    "circuits.extend(['aes', 'blackParrot', 'dynamicNode', 'gcd', 'ibex', 'jpeg', 'swerv', 'TinyRocket'])\n",
    "'''\n",
    "#circuits = ['aes', 'blackParrot', 'dynamicNode', 'gcd', 'ibex', 'jpeg', 'swerv', 'TinyRocket']\n",
    "circuits = [\"ispd19_test10\"]\n",
    "\n",
    "data_path = '/home/sheiny/workspace/Data/CNN/'\n",
    "npy_path = '/home/sheiny/workspace/Data/NPYCNN/'\n",
    "file_list = os.listdir(data_path)\n",
    "file_map = {}\n",
    "for file_name in file_list:\n",
    "    circuit = file_name.split('_')\n",
    "    if circuit[0] == 'ispd19':\n",
    "        file_map[circuit[0]+'_'+circuit[1]+'_'+circuit[2]] = file_name\n",
    "    else:\n",
    "        file_map[circuit[0]+'_'+circuit[1]] = file_name\n",
    "\n",
    "file_types = ['violatingNodes', 'surroundingViolNodes', 'nonViolatingNodes']\n",
    "\n",
    "for circuit in circuits:\n",
    "    print('Reading '+circuit+\" files\")\n",
    "    for file_type in file_types:\n",
    "        print(\"File: \"+file_type)\n",
    "        file_name = file_map[circuit+'_'+file_type]\n",
    "        names = file_name.split('_')\n",
    "        # Data (X)\n",
    "        print('loading ',file_name)\n",
    "        data = np.loadtxt(data_path+file_name, dtype=np.int32)\n",
    "        print('reshaping')\n",
    "        if names[0] == 'ispd19':\n",
    "            data = data.reshape(int(names[3]),23,23,6)\n",
    "        else:\n",
    "            data = data.reshape(int(names[2]),23,23,6)\n",
    "        if names[2] == 'nonViolatingNodes' or names[1] == 'nonViolatingNodes':# Undersample\n",
    "            selected_rows = np.random.choice(data.shape[0], size=int(0.1*len(data)), replace=False)\n",
    "            selected_rows.sort()\n",
    "            data = data[selected_rows, :]\n",
    "        np.save(npy_path+circuit+'_'+file_type+'.npy', data)\n",
    "        print('Done, final shape is: ',data.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
