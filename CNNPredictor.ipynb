{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb56f37",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7846cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "from enum import Enum\n",
    "import imblearn\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea80aed",
   "metadata": {},
   "source": [
    "# Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8209cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCNNModel(evalMetrics, learningRate, inputSize):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = inputSize))\n",
    "  model.add(tf.keras.layers.AveragePooling2D((3, 3)))\n",
    "#   model.add(tf.keras.layers.MaxPooling2D((3, 3))) #Test\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(128, activation = 'relu')) #Try to remove\n",
    "  model.add(tf.keras.layers.Dense(128, activation = 'relu')) #Try to remove\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics = evalMetrics)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9cc971",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727cd8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = %time pd.read_pickle('/data/AllCircuits.pkl', compression='zip')\n",
    "dfVal = df.sample(frac=0.2)\n",
    "df = df.drop(dfVal.index)\n",
    "labels = df.pop(df.columns.values[-1])\n",
    "valLabels = dfVal.pop(dfVal.columns.values[-1])\n",
    "trainHyperImages = np.array(df).reshape(len(df),22,33,33)\n",
    "valHyperImages = np.array(dfVal).reshape(len(dfVal),22,33,33)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21e8d067",
   "metadata": {},
   "source": [
    "There are lots of things I have seen make a model diverge.\n",
    "\n",
    "    Too high of a learning rate. You can often tell if this is the case if the loss begins to increase and then diverges to infinity.\n",
    "\n",
    "    I am not to familiar with the DNNClassifier but I am guessing it uses the categorical cross entropy cost function. This involves taking the log of the prediction which diverges as the prediction approaches zero. That is why people usually add a small epsilon value to the prediction to prevent this divergence. I am guessing the DNNClassifier probably does this or uses the tensorflow opp for it. Probably not the issue.\n",
    "\n",
    "    Other numerical stability issues can exist such as division by zero where adding the epsilon can help. Another less obvious one if the square root whose derivative can diverge if not properly simplified when dealing with finite precision numbers. Yet again I doubt this is the issue in the case of the DNNClassifier.\n",
    "\n",
    "    You may have an issue with the input data. Try calling assert not np.any(np.isnan(x)) on the input data to make sure you are not introducing the nan. Also make sure all of the target values are valid. Finally, make sure the data is properly normalized. You probably want to have the pixels in the range [-1, 1] and not [0, 255].\n",
    "\n",
    "    The labels must be in the domain of the loss function, so if using a logarithmic-based loss function all labels must be non-negative (as noted by evan pu and the comments below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e54192",
   "metadata": {},
   "source": [
    "# Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e5268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "numEpochs = 100\n",
    "learningRate = 0.001 #Eh?Predictor=0.05, default=0.001\n",
    "dropOut = 0.05 #Eh?Predictor=0.05\n",
    "evalMetrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "               tf.keras.metrics.FalsePositives(name='fp'),\n",
    "               tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "               tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall'),\n",
    "               tf.keras.metrics.AUC(name='auc')]\n",
    "\n",
    "inputSize = (22, 33, 33)\n",
    "\n",
    "model = makeCNNModel(evalMetrics, learningRate, inputSize)\n",
    "\n",
    "train_history = model.fit(x=trainHyperImages,\n",
    "                         y=labels,\n",
    "                         batch_size=batch_size,\n",
    "                         validation_data=(valHyperImages, valLabels),\n",
    "                         epochs=numEpochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c950647",
   "metadata": {},
   "source": [
    "# Generate Train and Test CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f8a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCircuits = ['/data/CSV/'+x+'/' for x in os.listdir('/data/CSV/')]\n",
    "# allCircuits = ['/data/CSV/jpeg/', '/data/CSV/aes/', '/data/CSV/swerv/']\n",
    "allCSVs = list()\n",
    "for circuit in allCircuits:\n",
    "  for csv in os.listdir(circuit):\n",
    "    allCSVs.append(circuit+csv)\n",
    "\n",
    "DFs = []\n",
    "for csv in allCSVs:\n",
    "  DFs.append(pd.read_csv(csv, dtype=np.float32, header=None))\n",
    "df = pd.concat(DFs)\n",
    "df.to_pickle('/data/AllCircuits.pkl', compression='zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
