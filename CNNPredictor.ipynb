{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb56f37",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7846cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea80aed",
   "metadata": {},
   "source": [
    "# Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8209cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCNNModel(evalMetrics, learningRate, inputSize):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = inputSize))\n",
    "#   model.add(tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = inputSize))\n",
    "  model.add(tf.keras.layers.AveragePooling2D((3, 3)))\n",
    "#   model.add(tf.keras.layers.MaxPooling2D((3, 3))) #Test\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(128, activation = 'relu')) #Try to remove\n",
    "  model.add(tf.keras.layers.Dense(128, activation = 'relu')) #Try to remove\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "#               optimizer = tf.keras.optimizers.experimental.SGD(),\n",
    "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics = evalMetrics)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9cc971",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCircuits = ['/data/CSV/'+x+'/' for x in os.listdir('/data/CSV/')]\n",
    "allCircuits.remove('/data/CSV/bp/')\n",
    "allPkl = []\n",
    "for circuit in allCircuits:\n",
    "  for pkl in os.listdir(circuit):\n",
    "    if '.pkl' not in pkl:\n",
    "      continue\n",
    "#     density = int(pkl[pkl.find('.')-2:pkl.find('.')])\n",
    "#     if density > 80:\n",
    "#       continue\n",
    "    if '80' not in pkl:\n",
    "      continue\n",
    "    allPkl.append(circuit+pkl)\n",
    "\n",
    "allDfs = [pd.read_pickle(x, compression='zip') for x in allPkl]\n",
    "df = pd.concat(allDfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727cd8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True) #Shuffle all rows\n",
    "dfVal = df.sample(frac=0.2)\n",
    "df = df.drop(dfVal.index)\n",
    "\n",
    "labels = df.pop(df.columns.values[-1])\n",
    "valLabels = dfVal.pop(dfVal.columns.values[-1])\n",
    "trainHyperImages = np.array(df).reshape(len(df),22,33,33)\n",
    "valHyperImages = np.array(dfVal).reshape(len(dfVal),22,33,33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e54192",
   "metadata": {},
   "source": [
    "# Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e5268b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sizeBatch = 32 # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "numEpochs = 50\n",
    "learningRate = 0.001 #Eh?Predictor=0.05, default=0.001\n",
    "evalMetrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "               tf.keras.metrics.FalsePositives(name='fp'),\n",
    "               tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "               tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall'),\n",
    "               tf.keras.metrics.AUC(name='auc')]\n",
    "\n",
    "inputSize = (22, 33, 33)\n",
    "\n",
    "model = makeCNNModel(evalMetrics, learningRate, inputSize)\n",
    "\n",
    "train_history = model.fit(x=trainHyperImages,\n",
    "                         y=labels,\n",
    "                         verbose=0, #0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "                         batch_size=sizeBatch,\n",
    "                         validation_data=(valHyperImages, valLabels),\n",
    "                         epochs=numEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d3781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_history.history['loss'][0:50])\n",
    "plt.plot(train_history.history['val_loss'][0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de5f4a",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ceb928",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('/data/model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72568c30",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a5a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('/data/model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c950647",
   "metadata": {},
   "source": [
    "# Compress All CSVs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e27142d4",
   "metadata": {},
   "source": [
    "allCircuits = ['/data/CSV/'+x+'/' for x in os.listdir('/data/CSV/')]\n",
    "allCircuits.sort()\n",
    "for circuit in allCircuits:\n",
    "  files = os.listdir(circuit)\n",
    "  files.sort()\n",
    "  for csv in files:\n",
    "    if 'viol' not in csv:\n",
    "      continue\n",
    "    if csv[0:csv.find('_viol')]+'.pkl' in files: #Already compressed\n",
    "      continue\n",
    "    dfViol = pd.read_csv(circuit+csv, dtype=np.float32, header=None)\n",
    "    dfSurround = pd.read_csv(circuit+csv[0:csv.find('viol')]+'surround.csv', dtype=np.float32, header=None)\n",
    "    df = pd.concat([dfViol, dfSurround])\n",
    "    df.to_pickle(circuit+csv[0:csv.find('_viol')]+'.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ee0a6",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb50f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_metrics(model, results):\n",
    "  m = {}\n",
    "  for name, value in zip(model.metrics_names, results):\n",
    "      m[name] = value\n",
    "  if m['precision'] + m['recall'] != 0:\n",
    "      f_score = 2 * ((m['precision'] * m['recall'])/(m['precision'] + m['recall']))\n",
    "      m['F-score'] = f_score\n",
    "  sqrt = math.sqrt((m['tp']+m['fp'])*(m['tp']+m['fn'])*(m['tn']+m['fp'])*(m['tn']+m['fn']))\n",
    "  if sqrt != 0:\n",
    "      mcc = ((m['tp'] * m['tn']) - (m['fp'] * m['fn']))/sqrt\n",
    "      m['MCC'] = mcc\n",
    "  return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562595fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeBatch = 32 # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "# testDF = %time pd.read_pickle('/data/CSV/swerv/cts_swerv_70.pkl', compression='zip')\n",
    "testDF = testDF.sample(frac=1).reset_index(drop=True) #Shuffle all rows\n",
    "testLabels = testDF.pop(testDF.columns.values[-1])\n",
    "testHyperImages = np.array(testDF).reshape(len(testDF),22,33,33)\n",
    "batch_size = 32\n",
    "baseline_results = model.evaluate(x=testHyperImages,\n",
    "                                  y=testLabels,\n",
    "                                  batch_size=sizeBatch)\n",
    "test_metrics = calculate_test_metrics(model, baseline_results)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80605bb1",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4afe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = sklearn.preprocessing.StandardScaler()\n",
    "# trainHyperImages = scaler.fit_transform(trainHyperImages)\n",
    "# valHyperImages = scaler.transform(valHyperImages)\n",
    "\n",
    "# scaler = sklearn.preprocessing.StandardScaler()\n",
    "# labels = df[33*33*22]\n",
    "# df[0:33*33*22-1] = scaler.fit_transform(df[0:33*33*22-1]).round(decimals=2)\n",
    "# df[33*33*22] = labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
