{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb56f37",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7846cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea80aed",
   "metadata": {},
   "source": [
    "# Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ac440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCNNModel(evalMetrics, learningRate, inputSize):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Conv2D(128, (3, 3), activation = 'relu', input_shape = inputSize))\n",
    "  model.add(tf.keras.layers.MaxPooling2D((3, 3)))\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "#               optimizer = tf.keras.optimizers.experimental.SGD(),\n",
    "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics = evalMetrics)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9cc971",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCircuits = ['/data/CSV/'+x+'/' for x in os.listdir('/data/CSV/')]\n",
    "allPkls = []\n",
    "for circuit in allCircuits:\n",
    "  for pkl in os.listdir(circuit):\n",
    "    if '.pkl' not in pkl:\n",
    "      continue\n",
    "    density = int(pkl[pkl.find('.')-2:pkl.find('.')])\n",
    "    if density == 79 or density == 81:\n",
    "      allPkls.append(circuit+pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e54192",
   "metadata": {},
   "source": [
    "# Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e5268b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sizeBatch = 64  # almost 10% of chance to have viol \\\n",
    "                # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "numEpochs = 50\n",
    "weights = {0: 0.5, 1: 50}\n",
    "learningRate = 0.001\n",
    "evalMetrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "               tf.keras.metrics.FalsePositives(name='fp'),\n",
    "               tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "               tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall'),\n",
    "               tf.keras.metrics.AUC(name='auc')]\n",
    "\n",
    "\n",
    "if os.path.exists('models/') == False:\n",
    "  os.mkdir('models/')\n",
    "\n",
    "models = [x for x in os.listdir('models/')]\n",
    "lastRunEpoch = 0\n",
    "inputSize = (22, 33, 33)\n",
    "model = None\n",
    "trainResultDF = pd.DataFrame()\n",
    "if len(models) > 0:\n",
    "  models.sort()\n",
    "  lastModel = models[-1]\n",
    "  lastRunEpoch = int(lastModel[lastModel.find('_')+1:lastModel.find('.')])\n",
    "  model = pickle.load(open('models/model_'+str(lastRunEpoch)+'.pkl', 'rb'))\n",
    "  trainResultDF = pickle.load(open('trainResultDF.pkl', 'rb'))\n",
    "else:\n",
    "  model = makeCNNModel(evalMetrics, learningRate, inputSize)\n",
    "\n",
    "for epoch in range(lastRunEpoch+1, numEpochs):\n",
    "  random.shuffle(allPkls)\n",
    "  for pkl in allPkls:\n",
    "    trainDf = pd.read_pickle(pkl, compression='zip')\n",
    "    trainDf = trainDf.reset_index(drop=True)\n",
    "    valDf = trainDf.sample(frac=0.2)\n",
    "    trainDf = trainDf.drop(valDf.index)\n",
    "\n",
    "    labels = trainDf.pop(trainDf.columns.values[-1])\n",
    "    valLabels = valDf.pop(valDf.columns.values[-1])\n",
    "    trainHyperImages = np.array(trainDf).reshape(len(trainDf),22,33,33)\n",
    "    valHyperImages = np.array(valDf).reshape(len(valDf),22,33,33)\n",
    "    print('Epoch: ',epoch,' Training with:', pkl)\n",
    "    train_history = model.fit(x=trainHyperImages,\n",
    "                             y=labels,\n",
    "                             verbose=2, #0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "                             batch_size=sizeBatch,\n",
    "                             validation_data=(valHyperImages, valLabels),\n",
    "                             class_weight=weights)\n",
    "    historyDf = pd.DataFrame(train_history.history)\n",
    "    historyDf['epoch'] = epoch\n",
    "    historyDf['design'] = pkl[pkl.rfind('/')+5:pkl.find('.')]\n",
    "    trainResultDF = pd.concat([trainResultDF, historyDf])\n",
    "  pickle.dump(model, open('models/model_'+str(epoch)+'.pkl', 'wb'))\n",
    "  pickle.dump(trainResultDF, open('trainResultDF.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de5f4a",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ceb928",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72568c30",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a5a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('exp5Models/model_49.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d3781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainResultDF = pickle.load(open('EXP5trainResultDF.pkl', 'rb'))\n",
    "trainResultDF.shape\n",
    "# plt.plot(train_history.history['loss'][0:50])\n",
    "# plt.plot(train_history.history['val_loss'][0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a697dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = 'jpeg_79'\n",
    "sortedDF = trainResultDF.loc[trainResultDF['design'] == design].sort_values(by=['epoch'])\n",
    "ytrain = [x for x in sortedDF['loss']]\n",
    "yval = [x for x in sortedDF['val_loss']]\n",
    "plt.plot(ytrain, label = \"ytrain\")\n",
    "plt.plot(yval, label = \"yval\")\n",
    "plt.legend()\n",
    "plt.title(design)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c950647",
   "metadata": {},
   "source": [
    "# Compress All CSVs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87644ce8",
   "metadata": {},
   "source": [
    "allCircuits = ['/data/CSV/'+x+'/' for x in os.listdir('/data/CSV/')]\n",
    "allCircuits.sort()\n",
    "for circuit in allCircuits:\n",
    "  files = os.listdir(circuit)\n",
    "  files.sort()\n",
    "  for csv in files:\n",
    "    if csv == 'cts_swerv_90_viol.csv' or csv == 'cts_swerv_89_viol.csv': #too many viol\n",
    "      continue\n",
    "    if 'viol' not in csv:\n",
    "      continue\n",
    "    if csv[0:csv.find('_viol')]+'.pkl' in files: #Already compressed\n",
    "      continue\n",
    "    print('Compressing ', csv[0:csv.find('_viol')])\n",
    "    dfViol = pd.read_csv(circuit+csv, dtype=np.float32, header=None)\n",
    "    dfSurround = pd.read_csv(circuit+csv[0:csv.find('viol')]+'surround.csv', dtype=np.float32, header=None)\n",
    "    dfNonViol = pd.read_csv(circuit+csv[0:csv.find('viol')]+'nonViol.csv', dtype=np.float32, header=None)\n",
    "    df = pd.concat([dfViol, dfSurround, dfNonViol], ignore_index=True)\n",
    "    df.to_pickle(circuit+csv[0:csv.find('_viol')]+'.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ee0a6",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb50f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_metrics(model, results):\n",
    "  m = {}\n",
    "  for name, value in zip(model.metrics_names, results):\n",
    "      m[name] = value\n",
    "  if m['precision'] + m['recall'] != 0:\n",
    "      f_score = 2 * ((m['precision'] * m['recall'])/(m['precision'] + m['recall']))\n",
    "      m['F-score'] = f_score\n",
    "  sqrt = math.sqrt((m['tp']+m['fp'])*(m['tp']+m['fn'])*(m['tn']+m['fp'])*(m['tn']+m['fn']))\n",
    "  if sqrt != 0:\n",
    "      mcc = ((m['tp'] * m['tn']) - (m['fp'] * m['fn']))/sqrt\n",
    "      m['MCC'] = mcc\n",
    "  return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = pd.read_pickle('/data/CSV/swerv/cts_swerv_80.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562595fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeBatch = 64 # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "# testDF = %time pd.read_pickle('/data/CSV/swerv/cts_swerv_70.pkl', compression='zip')\n",
    "testDF = testDF.sample(frac=1).reset_index(drop=True) #Shuffle all rows\n",
    "testLabels = testDF.pop(testDF.columns.values[-1])\n",
    "testHyperImages = np.array(testDF).reshape(len(testDF),22,33,33)\n",
    "batch_size = 32\n",
    "baseline_results = model.evaluate(x=testHyperImages,\n",
    "                                  y=testLabels,\n",
    "                                  batch_size=sizeBatch)\n",
    "test_metrics = calculate_test_metrics(model, baseline_results)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80605bb1",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4afe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = sklearn.preprocessing.StandardScaler()\n",
    "# trainHyperImages = scaler.fit_transform(trainHyperImages)\n",
    "# valHyperImages = scaler.transform(valHyperImages)\n",
    "\n",
    "# scaler = sklearn.preprocessing.StandardScaler()\n",
    "# labels = df[33*33*22]\n",
    "# df[0:33*33*22-1] = scaler.fit_transform(df[0:33*33*22-1]).round(decimals=2)\n",
    "# df[33*33*22] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9156d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(frac=1).reset_index(drop=True) #Shuffle all rows\n",
    "# dfVal = df.sample(frac=0.2)\n",
    "# df = df.drop(dfVal.index)\n",
    "\n",
    "# labels = df.pop(df.columns.values[-1])\n",
    "# valLabels = dfVal.pop(dfVal.columns.values[-1])\n",
    "# trainHyperImages = np.array(df).reshape(len(df),22,33,33)\n",
    "# valHyperImages = np.array(dfVal).reshape(len(dfVal),22,33,33)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
