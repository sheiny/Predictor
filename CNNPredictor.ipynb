{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb56f37",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9021c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea80aed",
   "metadata": {},
   "source": [
    "# Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ac440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN Model\n",
    "def makeFCNModel(evalMetrics, learningRate, inputSize):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = inputSize))\n",
    "  model.add(tf.keras.layers.MaxPooling2D((3, 3)))\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics = evalMetrics)\n",
    "  return model\n",
    "\n",
    "# CNN Model\n",
    "def makeCNNModel(evalMetrics, learningRate, inputSize):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = inputSize))\n",
    "  model.add(tf.keras.layers.MaxPooling2D((3, 3)))\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(128, activation = 'relu'))#Dense\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics = evalMetrics)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9cc971",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcbc6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('benchmark.pkl', compression='zip')\n",
    "# Get ONLY completelly routed circuits\n",
    "df2 = df.loc[df['FDRTotal'] == 0]\n",
    "# Get all designs to train\n",
    "circuitsToTrain = [x for x in df2.loc[df2['Design'].str.contains('80') == False].sort_values(by=['Design'])['Design']]\n",
    "\n",
    "allPkls = ['/data/CSV/' + x[0:-3] + '/cts_' + x + '.pkl' for x in circuitsToTrain]\n",
    "allPkls = [x for x in allPkls if os.path.exists(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad17a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only designs within 75 and 85 except 80\n",
    "allPkls = [x for x in allPkls if int(re.findall(r'\\d+', x)[0]) < 86 and int(re.findall(r'\\d+', x)[0]) > 74]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e54192",
   "metadata": {},
   "source": [
    "# Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f205e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = 'fcn/'\n",
    "model = 'fcn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06160ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = 'cnn/'\n",
    "model = 'cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f6227",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeBatch = 64  # almost 10% of chance to have viol \\\n",
    "                # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "numEpochs = 10\n",
    "weights = {0: 0.5, 1: 50}\n",
    "learningRate = 0.001\n",
    "evalMetrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "               tf.keras.metrics.FalsePositives(name='fp'),\n",
    "               tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "               tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall'),\n",
    "               tf.keras.metrics.AUC(name='auc')]\n",
    "\n",
    "\n",
    "if os.path.exists(modelPath) == False:\n",
    "  os.mkdir(modelPath)\n",
    "\n",
    "models = [x for x in os.listdir(modelPath)]\n",
    "lastRunEpoch = 0\n",
    "inputSize = (22, 33, 33)\n",
    "model = None\n",
    "trainResultDF = pd.DataFrame()\n",
    "if len(models) > 0:\n",
    "  models.sort()\n",
    "  lastModel = models[-1]\n",
    "  lastRunEpoch = int(lastModel[lastModel.find('_')+1:lastModel.find('.')])\n",
    "  model = pickle.load(open(modelPath+'model_'+str(lastRunEpoch)+'.pkl', 'rb'))\n",
    "  trainResultDF = pickle.load(open('trainResultDF.pkl', 'rb'))\n",
    "else:\n",
    "  model = makeFCNModel(evalMetrics, learningRate, inputSize) if model == 'fcn' else makeCNNModel(evalMetrics, learningRate, inputSize)\n",
    "\n",
    "for epoch in range(lastRunEpoch+1, numEpochs):\n",
    "  random.shuffle(allPkls)\n",
    "  for pkl in allPkls:\n",
    "    trainDf = pd.read_pickle(pkl, compression='zip')\n",
    "    trainDf = trainDf.reset_index(drop=True)\n",
    "    valDf = trainDf.sample(frac=0.2)\n",
    "    trainDf = trainDf.drop(valDf.index)\n",
    "\n",
    "    labels = trainDf.pop(trainDf.columns.values[-1])\n",
    "    valLabels = valDf.pop(valDf.columns.values[-1])\n",
    "    trainHyperImages = np.array(trainDf).reshape(len(trainDf),22,33,33)\n",
    "    valHyperImages = np.array(valDf).reshape(len(valDf),22,33,33)\n",
    "    print('Epoch: ',epoch,' Training with:', pkl)\n",
    "    train_history = model.fit(x=trainHyperImages,\n",
    "                             y=labels,\n",
    "                             verbose=2, #0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "                             batch_size=sizeBatch,\n",
    "                             validation_data=(valHyperImages, valLabels),\n",
    "                             class_weight=weights)\n",
    "    historyDf = pd.DataFrame(train_history.history)\n",
    "    historyDf['epoch'] = epoch\n",
    "    historyDf['design'] = pkl[pkl.rfind('/')+5:pkl.find('.')]\n",
    "    trainResultDF = pd.concat([trainResultDF, historyDf])\n",
    "  pickle.dump(model, open(modelPath+'model_'+str(epoch)+'.pkl', 'wb'))\n",
    "  pickle.dump(trainResultDF, open('trainResultDF.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de5f4a",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ceb928",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72568c30",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a5a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('exp9Models/model_4.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d3781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainResultDF = pickle.load(open('EXP9trainResultDF.pkl', 'rb'))\n",
    "trainResultDF.shape\n",
    "# plt.plot(train_history.history['loss'][0:50])\n",
    "# plt.plot(train_history.history['val_loss'][0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b50ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(min(trainResultDF['epoch']), max(trainResultDF['epoch'])+1):\n",
    "  loss = sum(trainResultDF.loc[trainResultDF['epoch'] == epoch]['loss'])\n",
    "  valLoss = sum(trainResultDF.loc[trainResultDF['epoch'] == epoch]['val_loss'])\n",
    "  print('epoch:', epoch, ' loss: ', loss, ' valLoss: ', valLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65339ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainResultDF.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a697dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = 'jpeg_79'\n",
    "sortedDF = trainResultDF.loc[trainResultDF['design'] == design].sort_values(by=['epoch'])\n",
    "ytrain = [x for x in sortedDF['loss']]\n",
    "yval = [x for x in sortedDF['val_loss']]\n",
    "plt.plot(ytrain, label = \"ytrain\")\n",
    "plt.plot(yval, label = \"yval\")\n",
    "plt.legend()\n",
    "plt.title(design)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ee0a6",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb50f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_metrics(model, results):\n",
    "  m = {}\n",
    "  for name, value in zip(model.metrics_names, results):\n",
    "      m[name] = value\n",
    "  if m['precision'] + m['recall'] != 0:\n",
    "      f_score = 2 * ((m['precision'] * m['recall'])/(m['precision'] + m['recall']))\n",
    "      m['F-score'] = f_score\n",
    "  sqrt = math.sqrt((m['tp']+m['fp'])*(m['tp']+m['fn'])*(m['tn']+m['fp'])*(m['tn']+m['fn']))\n",
    "  if sqrt != 0:\n",
    "      mcc = ((m['tp'] * m['tn']) - (m['fp'] * m['fn']))/sqrt\n",
    "      m['MCC'] = mcc\n",
    "  return m"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0d42ea9",
   "metadata": {},
   "source": [
    "sizeBatch = 64 # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "# testDF = %time pd.read_pickle('/data/CSV/swerv/cts_swerv_70.pkl', compression='zip')\n",
    "testDF = testDF.sample(frac=1).reset_index(drop=True) #Shuffle all rows\n",
    "testLabels = testDF.pop(testDF.columns.values[-1])\n",
    "testHyperImages = np.array(testDF).reshape(len(testDF),22,33,33)\n",
    "baseline_results = model.evaluate(x=testHyperImages,\n",
    "                                  y=testLabels,\n",
    "                                  batch_size=sizeBatch)\n",
    "test_metrics = calculate_test_metrics(model, baseline_results)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d9a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeBatch = 64 # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "# testPath = '/data/CSVWhole/jpeg/'\n",
    "# testPkls = [testPath+x for x in  os.listdir(testPath)]\n",
    "for circuit in os.listdir('/data/CSVWhole/'):\n",
    "  i = 0\n",
    "  resultDF = pd.DataFrame()\n",
    "  for pkl in ['/data/CSVWhole/'+circuit+'/'+x for x in os.listdir('/data/CSVWhole/'+circuit)]:\n",
    "    print(circuit, i, pkl)\n",
    "    testDF = pd.read_pickle(pkl, compression='zip')\n",
    "    testDF = testDF.sample(frac=1).reset_index(drop=True) #Shuffle all rows\n",
    "    testLabels = testDF.pop(testDF.columns.values[-1])\n",
    "    testHyperImages = np.array(testDF).reshape(len(testDF),22,33,33)\n",
    "    baseline_results = model.evaluate(x=testHyperImages,\n",
    "                                      y=testLabels,\n",
    "                                      batch_size=sizeBatch)\n",
    "    test_metrics = calculate_test_metrics(model, baseline_results)\n",
    "    testDF = pd.DataFrame(test_metrics, index=[i])\n",
    "    testDF['design'] = circuit\n",
    "    resultDF = pd.concat([resultDF, testDF], ignore_index=True)\n",
    "    i += 1\n",
    "resultDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625a410",
   "metadata": {},
   "source": [
    "# Benchmark Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4398ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('benchmark.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ccb70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot Routing Runtime Break Down\n",
    "dfRuntime = df.loc[df['Design'].str.contains('80')].sort_values(by=['COMPONENTS'], ascending=False)\n",
    "dfRuntime['Design'] = [x[0:x.rfind('_')] for x in dfRuntime['Design']]\n",
    "dfRuntime = dfRuntime.set_index('Design')\n",
    "dfRuntime = dfRuntime[['GR', 'IDR', 'FDR']]\n",
    "ax = dfRuntime.plot.bar(stacked=True)\n",
    "ax.set_ylabel('Runtime in seconds')\n",
    "ax.set_xlabel('Designs (80% row utilization)')\n",
    "ax.legend([\"Global Routing\", \"Initial Detailed Routing\", \"Complete Detailed Routing\"])\n",
    "plt.title('Routing Runtime Break Down For 80% Row Utilization Designs')\n",
    "# plt.savefig('routing_runtime.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94c1a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot Routing Runtime Break Down\n",
    "dfRuntime = df.loc[df['Design'].str.contains('80')].sort_values(by=['COMPONENTS'], ascending=False)\n",
    "dfRuntime['Design'] = [x[0:x.rfind('_')] for x in dfRuntime['Design']]\n",
    "dfRuntime = dfRuntime.set_index('Design')\n",
    "dfRuntime = dfRuntime[['IDRShort']]\n",
    "ax = dfRuntime.plot.bar(stacked=True)\n",
    "ax.set_ylabel('Initial Detailed Routing Violations (IDRVs)')\n",
    "ax.set_xlabel('Designs (80% row utilization)')\n",
    "plt.title('Number of IDRVs For 80% Row Utilization Designs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb448a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg IDR short (considering full routed circuits only)\n",
    "idrShort = []\n",
    "for x in range(70, 91):\n",
    "  tempDf = df.loc[df['Design'].str.contains(str(x))]\n",
    "  tempDf = tempDf.loc[tempDf['FDRTotal'] == 0]\n",
    "  avgIDRShort = sum(tempDf['IDRShort']/len(tempDf))\n",
    "  idrShort.append(avgIDRShort)\n",
    "\n",
    "plt.plot([y for y in range(70, 91)], idrShort, color = 'r')\n",
    "plt.xlabel(\"Design Density (Row Utilization %)\")\n",
    "plt.ylabel(\"Initial Detailed Routing Short Violations (IDRV)\")\n",
    "plt.title('Average IDR Short x Row Utilization (Only DRV Free Designs)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c199b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg IDR short (considering full routed circuits only)\n",
    "fdrRuntime = []\n",
    "for x in range(70, 91):\n",
    "  tempDf = df.loc[df['Design'].str.contains(str(x))]\n",
    "  tempDf = tempDf.loc[tempDf['FDRTotal'] == 0]\n",
    "  fdr = sum(tempDf['FDR']/len(tempDf))\n",
    "  fdrRuntime.append(fdr)\n",
    "\n",
    "plt.plot([y for y in range(70, 91)], fdrRuntime, color = 'r')\n",
    "plt.xlabel(\"Design Density (Row Utilization %)\")\n",
    "plt.ylabel(\"Runtime (seconds)\")\n",
    "plt.title('Average Runtime to complete routing (Only DRV Free Designs)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735fc326",
   "metadata": {},
   "source": [
    "# Benchmark Info"
   ]
  },
  {
   "cell_type": "raw",
   "id": "938c0a92",
   "metadata": {},
   "source": [
    "def numDRVs(file):\n",
    "  shortViol = 0\n",
    "  totalViol = 0\n",
    "  for line in open(file, 'r').readlines():\n",
    "    if 'Metal Short' in line:\n",
    "      shortViol += 1\n",
    "    if 'Total Violations' in line:\n",
    "      totalViol = int(line.split(' ')[5])\n",
    "  return [shortViol, totalViol]\n",
    "\n",
    "def getDefInfo(file):\n",
    "  info = {x:0 for x in ['COMPONENTS', 'NETS', 'SPECIALNETS', 'PINS', 'BLOCKAGES']}\n",
    "  for line in open(file, 'r').readlines():\n",
    "    tokens = line.split(' ')\n",
    "    if tokens[0] in info:\n",
    "      info[tokens[0]] = int(tokens[1])\n",
    "  return info\n",
    "\n",
    "def getRuntime(file):\n",
    "  runtime = {x:-1 for x in ['GR', 'IDR', 'FDR']}\n",
    "  val = []\n",
    "  for line in open(file,\"r\"):\n",
    "      val.append(int(line.split(' ')[0]))\n",
    "  runtime['GR'] = val[0]\n",
    "  runtime['IDR'] = val[1]\n",
    "  runtime['FDR'] = val[2]\n",
    "  return runtime\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "benchmarkPath = '/home/sheiny/workspace/Benchmarks/RoutedOpenCores/'\n",
    "allCircuits = [benchmarkPath+circuit+'/base/' for circuit in os.listdir(benchmarkPath) if os.path.exists(benchmarkPath+circuit+'/base/')]\n",
    "\n",
    "allCircuits.remove(benchmarkPath+'bp/base/')#Pad problem (too much congested at bottom left)\n",
    "allCircuits.remove(benchmarkPath+'gcd/base/')#Too small\n",
    "\n",
    "for circuit in allCircuits:\n",
    "  for csv in os.listdir(circuit):\n",
    "    if 'Runtime' not in csv:\n",
    "      continue\n",
    "    design = csv[csv.find('_')+1:csv.find('Runtime')]\n",
    "\n",
    "    IDRShort, IDRTotal = numDRVs(circuit+'cts_'+design+'FirstDR.rpt')\n",
    "    FDRShort, FDRTotal = numDRVs(circuit+'cts_'+design+'FinalDR.rpt')\n",
    "\n",
    "    info = getDefInfo(circuit+'cts_'+design+'.def')\n",
    "    drvs = {'IDRShort':IDRShort, 'IDRTotal':IDRTotal, 'FDRShort':FDRShort, 'FDRTotal':FDRTotal}\n",
    "    runtime = getRuntime(circuit+'cts_'+design+'Runtime.out')\n",
    "    dfVals = {'Design':design}\n",
    "    dfVals.update(info)\n",
    "    dfVals.update(drvs)\n",
    "    dfVals.update(runtime)\n",
    "    dfTemp = pd.DataFrame(dfVals, index=[0])\n",
    "    df = pd.concat([df, dfTemp], ignore_index=True)\n",
    "df.to_pickle('benchmark.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71d3b33",
   "metadata": {},
   "source": [
    "# Compress All CSVs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e839aec",
   "metadata": {},
   "source": [
    "# MULTIPLE CSVs per circuit (Train)\n",
    "allCircuits = ['/data/CSV/'+x+'/' for x in os.listdir('/data/CSV/')]\n",
    "allCircuits.sort()\n",
    "for circuit in allCircuits:\n",
    "  files = os.listdir(circuit)\n",
    "  files.sort()\n",
    "  for csv in files:\n",
    "    if csv == 'cts_swerv_90_viol.csv' or csv == 'cts_swerv_89_viol.csv': #too many viol\n",
    "      continue\n",
    "    if 'viol' not in csv:\n",
    "      continue\n",
    "    if csv[0:csv.find('_viol')]+'.pkl' in files: #Already compressed\n",
    "      continue\n",
    "    print('Compressing ', csv[0:csv.find('_viol')])\n",
    "    dfViol = pd.read_csv(circuit+csv, dtype=np.float32, header=None)\n",
    "    dfSurround = pd.read_csv(circuit+csv[0:csv.find('viol')]+'surround.csv', dtype=np.float32, header=None)\n",
    "    dfNonViol = pd.read_csv(circuit+csv[0:csv.find('viol')]+'nonViol.csv', dtype=np.float32, header=None)\n",
    "    df = pd.concat([dfViol, dfSurround, dfNonViol], ignore_index=True)\n",
    "    df.to_pickle(circuit+csv[0:csv.find('_viol')]+'.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ceaf26c9",
   "metadata": {},
   "source": [
    "# A SINGLE CSV per circuit (TEST)\n",
    "allCircuits = ['/data/CSV/'+x+'/' for x in os.listdir('/data/CSV/')]\n",
    "allCircuits.sort()\n",
    "for circuit in allCircuits:\n",
    "  files = os.listdir(circuit)\n",
    "  files.sort()\n",
    "  for csv in files:\n",
    "    if '.csv' not in csv:\n",
    "      continue\n",
    "    if csv[0:csv.find('.')]+'_0.pkl' in files: #Already compressed\n",
    "      print('skipping ',csv)\n",
    "      continue\n",
    "\n",
    "    i = 0\n",
    "    print('Compressing ', csv[0:csv.find('.')])\n",
    "    for df in pd.read_csv(circuit+csv, dtype=np.float32, header=None, chunksize=10000):\n",
    "      df.to_pickle(circuit+csv[0:csv.find('.')]+'_'+str(i)+'.pkl', compression='zip')\n",
    "      i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80605bb1",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4afe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = sklearn.preprocessing.StandardScaler()\n",
    "# trainHyperImages = scaler.fit_transform(trainHyperImages)\n",
    "# valHyperImages = scaler.transform(valHyperImages)\n",
    "\n",
    "# scaler = sklearn.preprocessing.StandardScaler()\n",
    "# labels = df[33*33*22]\n",
    "# df[0:33*33*22-1] = scaler.fit_transform(df[0:33*33*22-1]).round(decimals=2)\n",
    "# df[33*33*22] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9156d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(frac=1).reset_index(drop=True) #Shuffle all rows\n",
    "# dfVal = df.sample(frac=0.2)\n",
    "# df = df.drop(dfVal.index)\n",
    "\n",
    "# labels = df.pop(df.columns.values[-1])\n",
    "# valLabels = dfVal.pop(dfVal.columns.values[-1])\n",
    "# trainHyperImages = np.array(df).reshape(len(df),22,33,33)\n",
    "# valHyperImages = np.array(dfVal).reshape(len(dfVal),22,33,33)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
