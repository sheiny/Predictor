{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb56f37",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9021c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea80aed",
   "metadata": {},
   "source": [
    "# Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ac440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCNNModel(evalMetrics, learningRate, inputSize):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = inputSize))\n",
    "  model.add(tf.keras.layers.MaxPooling2D((3, 3)))\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "#               optimizer = tf.keras.optimizers.experimental.SGD(),\n",
    "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics = evalMetrics)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9cc971",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allCircuits = ['/data/CSV/'+x+'/' for x in os.listdir('/data/CSV/')]\n",
    "# allPkls = []\n",
    "# for circuit in allCircuits:\n",
    "#   for pkl in os.listdir(circuit):\n",
    "#     if '.pkl' not in pkl:\n",
    "#       continue\n",
    "#     density = int(pkl[pkl.find('.')-2:pkl.find('.')])\n",
    "#     if density == 79 or density == 81:\n",
    "#       allPkls.append(circuit+pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d747a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all completelly routed circuits\n",
    "df2 = df.loc[df['FDRTotal'] == 0]\n",
    "# Get all designs to train\n",
    "circuitsToTrain = [x for x in df2.loc[df2['Design'].str.contains('80') == False].sort_values(by=['Design'])['Design']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcbc6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all completelly routed circuits\n",
    "df2 = df.loc[df['FDRTotal'] == 0]\n",
    "# Get all designs to train\n",
    "circuitsToTrain = [x for x in df2.loc[df2['Design'].str.contains('80') == False].sort_values(by=['Design'])['Design']]\n",
    "\n",
    "allPkls = ['/data/CSV/' + x[0:-3] + '/cts_' + x + '.pkl' for x in circuitsToTrain]\n",
    "allPkls = [x for x in allPkls if os.path.exists(x)]\n",
    "\n",
    "# Get only designs within 75 and 85 except 80\n",
    "allPkls = [x for x in allPkls if int(re.findall(r'\\d+', x)[0]) < 86 and int(re.findall(r'\\d+', x)[0]) > 74]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e54192",
   "metadata": {},
   "source": [
    "# Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f6227",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeBatch = 64  # almost 10% of chance to have viol \\\n",
    "                # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "numEpochs = 100\n",
    "weights = {0: 0.5, 1: 50}\n",
    "learningRate = 0.001\n",
    "evalMetrics = [tf.keras.metrics.TruePositives(name='tp'),\n",
    "               tf.keras.metrics.FalsePositives(name='fp'),\n",
    "               tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "               tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall'),\n",
    "               tf.keras.metrics.AUC(name='auc')]\n",
    "\n",
    "\n",
    "if os.path.exists('models/') == False:\n",
    "  os.mkdir('models/')\n",
    "\n",
    "models = [x for x in os.listdir('models/')]\n",
    "lastRunEpoch = 0\n",
    "inputSize = (22, 33, 33)\n",
    "model = None\n",
    "trainResultDF = pd.DataFrame()\n",
    "if len(models) > 0:\n",
    "  models.sort()\n",
    "  lastModel = models[-1]\n",
    "  lastRunEpoch = int(lastModel[lastModel.find('_')+1:lastModel.find('.')])\n",
    "  model = pickle.load(open('models/model_'+str(lastRunEpoch)+'.pkl', 'rb'))\n",
    "  trainResultDF = pickle.load(open('trainResultDF.pkl', 'rb'))\n",
    "else:\n",
    "  model = makeCNNModel(evalMetrics, learningRate, inputSize)\n",
    "\n",
    "for epoch in range(lastRunEpoch+1, numEpochs):\n",
    "  random.shuffle(allPkls)\n",
    "  for pkl in allPkls:\n",
    "    trainDf = pd.read_pickle(pkl, compression='zip')\n",
    "    trainDf = trainDf.reset_index(drop=True)\n",
    "    valDf = trainDf.sample(frac=0.2)\n",
    "    trainDf = trainDf.drop(valDf.index)\n",
    "\n",
    "    labels = trainDf.pop(trainDf.columns.values[-1])\n",
    "    valLabels = valDf.pop(valDf.columns.values[-1])\n",
    "    trainHyperImages = np.array(trainDf).reshape(len(trainDf),22,33,33)\n",
    "    valHyperImages = np.array(valDf).reshape(len(valDf),22,33,33)\n",
    "    print('Epoch: ',epoch,' Training with:', pkl)\n",
    "    train_history = model.fit(x=trainHyperImages,\n",
    "                             y=labels,\n",
    "                             verbose=2, #0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "                             batch_size=sizeBatch,\n",
    "                             validation_data=(valHyperImages, valLabels),\n",
    "                             class_weight=weights)\n",
    "    historyDf = pd.DataFrame(train_history.history)\n",
    "    historyDf['epoch'] = epoch\n",
    "    historyDf['design'] = pkl[pkl.rfind('/')+5:pkl.find('.')]\n",
    "    trainResultDF = pd.concat([trainResultDF, historyDf])\n",
    "  pickle.dump(model, open('models/model_'+str(epoch)+'.pkl', 'wb'))\n",
    "  pickle.dump(trainResultDF, open('trainResultDF.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de5f4a",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ceb928",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72568c30",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a5a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('exp9Models/model_4.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d3781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainResultDF = pickle.load(open('EXP9trainResultDF.pkl', 'rb'))\n",
    "trainResultDF.shape\n",
    "# plt.plot(train_history.history['loss'][0:50])\n",
    "# plt.plot(train_history.history['val_loss'][0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b50ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(min(trainResultDF['epoch']), max(trainResultDF['epoch'])+1):\n",
    "  loss = sum(trainResultDF.loc[trainResultDF['epoch'] == epoch]['loss'])\n",
    "  valLoss = sum(trainResultDF.loc[trainResultDF['epoch'] == epoch]['val_loss'])\n",
    "  print('epoch:', epoch, ' loss: ', loss, ' valLoss: ', valLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65339ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainResultDF.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a697dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = 'jpeg_79'\n",
    "sortedDF = trainResultDF.loc[trainResultDF['design'] == design].sort_values(by=['epoch'])\n",
    "ytrain = [x for x in sortedDF['loss']]\n",
    "yval = [x for x in sortedDF['val_loss']]\n",
    "plt.plot(ytrain, label = \"ytrain\")\n",
    "plt.plot(yval, label = \"yval\")\n",
    "plt.legend()\n",
    "plt.title(design)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c950647",
   "metadata": {},
   "source": [
    "# Compress All CSVs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87644ce8",
   "metadata": {},
   "source": [
    "# MULTIPLE CSVs per circuit\n",
    "allCircuits = ['/data/CSV/'+x+'/' for x in os.listdir('/data/CSV/')]\n",
    "allCircuits.sort()\n",
    "for circuit in allCircuits:\n",
    "  files = os.listdir(circuit)\n",
    "  files.sort()\n",
    "  for csv in files:\n",
    "    if csv == 'cts_swerv_90_viol.csv' or csv == 'cts_swerv_89_viol.csv': #too many viol\n",
    "      continue\n",
    "    if 'viol' not in csv:\n",
    "      continue\n",
    "    if csv[0:csv.find('_viol')]+'.pkl' in files: #Already compressed\n",
    "      continue\n",
    "    print('Compressing ', csv[0:csv.find('_viol')])\n",
    "    dfViol = pd.read_csv(circuit+csv, dtype=np.float32, header=None)\n",
    "    dfSurround = pd.read_csv(circuit+csv[0:csv.find('viol')]+'surround.csv', dtype=np.float32, header=None)\n",
    "    dfNonViol = pd.read_csv(circuit+csv[0:csv.find('viol')]+'nonViol.csv', dtype=np.float32, header=None)\n",
    "    df = pd.concat([dfViol, dfSurround, dfNonViol], ignore_index=True)\n",
    "    df.to_pickle(circuit+csv[0:csv.find('_viol')]+'.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bee2953",
   "metadata": {},
   "source": [
    "# A SINGLE CSV per circuit\n",
    "allCircuits = ['/data/CSV/'+x+'/' for x in os.listdir('/data/CSV/')]\n",
    "allCircuits.sort()\n",
    "for circuit in allCircuits:\n",
    "  files = os.listdir(circuit)\n",
    "  files.sort()\n",
    "  for csv in files:\n",
    "    if '.csv' not in csv:\n",
    "      continue\n",
    "    if csv[0:csv.find('.')]+'_0.pkl' in files: #Already compressed\n",
    "      print('skipping ',csv)\n",
    "      continue\n",
    "\n",
    "    i = 0\n",
    "    print('Compressing ', csv[0:csv.find('.')])\n",
    "    for df in pd.read_csv(circuit+csv, dtype=np.float32, header=None, chunksize=10000):\n",
    "      df.to_pickle(circuit+csv[0:csv.find('.')]+'_'+str(i)+'.pkl', compression='zip')\n",
    "      i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ee0a6",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb50f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_metrics(model, results):\n",
    "  m = {}\n",
    "  for name, value in zip(model.metrics_names, results):\n",
    "      m[name] = value\n",
    "  if m['precision'] + m['recall'] != 0:\n",
    "      f_score = 2 * ((m['precision'] * m['recall'])/(m['precision'] + m['recall']))\n",
    "      m['F-score'] = f_score\n",
    "  sqrt = math.sqrt((m['tp']+m['fp'])*(m['tp']+m['fn'])*(m['tn']+m['fp'])*(m['tn']+m['fn']))\n",
    "  if sqrt != 0:\n",
    "      mcc = ((m['tp'] * m['tn']) - (m['fp'] * m['fn']))/sqrt\n",
    "      m['MCC'] = mcc\n",
    "  return m"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0d42ea9",
   "metadata": {},
   "source": [
    "sizeBatch = 64 # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "# testDF = %time pd.read_pickle('/data/CSV/swerv/cts_swerv_70.pkl', compression='zip')\n",
    "testDF = testDF.sample(frac=1).reset_index(drop=True) #Shuffle all rows\n",
    "testLabels = testDF.pop(testDF.columns.values[-1])\n",
    "testHyperImages = np.array(testDF).reshape(len(testDF),22,33,33)\n",
    "baseline_results = model.evaluate(x=testHyperImages,\n",
    "                                  y=testLabels,\n",
    "                                  batch_size=sizeBatch)\n",
    "test_metrics = calculate_test_metrics(model, baseline_results)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d9a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeBatch = 64 # is important to ensure that each batch has a decent chance of containing a few positive samples\n",
    "# testPath = '/data/CSVWhole/jpeg/'\n",
    "# testPkls = [testPath+x for x in  os.listdir(testPath)]\n",
    "for circuit in os.listdir('/data/CSVWhole/'):\n",
    "  i = 0\n",
    "  resultDF = pd.DataFrame()\n",
    "  for pkl in ['/data/CSVWhole/'+circuit+'/'+x for x in os.listdir('/data/CSVWhole/'+circuit)]:\n",
    "    print(circuit, i, pkl)\n",
    "    testDF = pd.read_pickle(pkl, compression='zip')\n",
    "    testDF = testDF.sample(frac=1).reset_index(drop=True) #Shuffle all rows\n",
    "    testLabels = testDF.pop(testDF.columns.values[-1])\n",
    "    testHyperImages = np.array(testDF).reshape(len(testDF),22,33,33)\n",
    "    baseline_results = model.evaluate(x=testHyperImages,\n",
    "                                      y=testLabels,\n",
    "                                      batch_size=sizeBatch)\n",
    "    test_metrics = calculate_test_metrics(model, baseline_results)\n",
    "    testDF = pd.DataFrame(test_metrics, index=[i])\n",
    "    testDF['design'] = circuit\n",
    "    resultDF = pd.concat([resultDF, testDF], ignore_index=True)\n",
    "    i += 1\n",
    "resultDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735fc326",
   "metadata": {},
   "source": [
    "# Benchmark Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numDRVs(file):\n",
    "  shortViol = 0\n",
    "  totalViol = 0\n",
    "  for line in open(file, 'r').readlines():\n",
    "    if 'Metal Short' in line:\n",
    "      shortViol += 1\n",
    "    if 'Total Violations' in line:\n",
    "      totalViol = int(line.split(' ')[5])\n",
    "  return [shortViol, totalViol]\n",
    "\n",
    "def getDefInfo(file):\n",
    "  info = {x:0 for x in ['COMPONENTS', 'NETS', 'SPECIALNETS', 'PINS', 'BLOCKAGES']}\n",
    "  for line in open(file, 'r').readlines():\n",
    "    tokens = line.split(' ')\n",
    "    if tokens[0] in info:\n",
    "      info[tokens[0]] = int(tokens[1])\n",
    "  return info\n",
    "\n",
    "def getRuntime(file):\n",
    "  runtime = {x:-1 for x in ['GR', 'IDR', 'FDR']}\n",
    "  val = []\n",
    "  for line in open(file,\"r\"):\n",
    "      val.append(int(line.split(' ')[0]))\n",
    "  runtime['GR'] = val[0]\n",
    "  runtime['IDR'] = val[1]\n",
    "  runtime['FDR'] = val[2]\n",
    "  return runtime\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "benchmarkPath = '/home/sheiny/workspace/Benchmarks/RoutedOpenCores/'\n",
    "allCircuits = [benchmarkPath+circuit+'/base/' for circuit in os.listdir(benchmarkPath) if os.path.exists(benchmarkPath+circuit+'/base/')]\n",
    "\n",
    "allCircuits.remove(benchmarkPath+'bp/base/')#Pad problem (too much congested at bottom left)\n",
    "allCircuits.remove(benchmarkPath+'gcd/base/')#Too small\n",
    "\n",
    "for circuit in allCircuits:\n",
    "  for csv in os.listdir(circuit):\n",
    "    if 'Runtime' not in csv:\n",
    "      continue\n",
    "    design = csv[csv.find('_')+1:csv.find('Runtime')]\n",
    "\n",
    "    IDRShort, IDRTotal = numDRVs(circuit+'cts_'+design+'FirstDR.rpt')\n",
    "    FDRShort, FDRTotal = numDRVs(circuit+'cts_'+design+'FinalDR.rpt')\n",
    "\n",
    "    info = getDefInfo(circuit+'cts_'+design+'.def')\n",
    "    drvs = {'IDRShort':IDRShort, 'IDRTotal':IDRTotal, 'FDRShort':FDRShort, 'FDRTotal':FDRTotal}\n",
    "    runtime = getRuntime(circuit+'cts_'+design+'Runtime.out')\n",
    "    dfVals = {'Design':design}\n",
    "    dfVals.update(info)\n",
    "    dfVals.update(drvs)\n",
    "    dfVals.update(runtime)\n",
    "    dfTemp = pd.DataFrame(dfVals, index=[0])\n",
    "    df = pd.concat([df, dfTemp], ignore_index=True)\n",
    "df.to_pickle('benchmark.pkl', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7cf7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print circuit from table\n",
    "# TODO: probably use ratio isntead (IDRShort/IDRTotal)\n",
    "result = df.loc[df['Design'].str.contains(\"jpeg\")].sort_values(by=['Design'])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80605bb1",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4afe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = sklearn.preprocessing.StandardScaler()\n",
    "# trainHyperImages = scaler.fit_transform(trainHyperImages)\n",
    "# valHyperImages = scaler.transform(valHyperImages)\n",
    "\n",
    "# scaler = sklearn.preprocessing.StandardScaler()\n",
    "# labels = df[33*33*22]\n",
    "# df[0:33*33*22-1] = scaler.fit_transform(df[0:33*33*22-1]).round(decimals=2)\n",
    "# df[33*33*22] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9156d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(frac=1).reset_index(drop=True) #Shuffle all rows\n",
    "# dfVal = df.sample(frac=0.2)\n",
    "# df = df.drop(dfVal.index)\n",
    "\n",
    "# labels = df.pop(df.columns.values[-1])\n",
    "# valLabels = dfVal.pop(dfVal.columns.values[-1])\n",
    "# trainHyperImages = np.array(df).reshape(len(df),22,33,33)\n",
    "# valHyperImages = np.array(dfVal).reshape(len(dfVal),22,33,33)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
